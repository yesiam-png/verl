+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ ulimit -n 65535
++ pwd
+ PROJECT_DIR=/mnt/task_runtime/verl
+ CONFIG_PATH=/mnt/task_runtime/verl/examples/sglang_multiturn/config
+ python3 -m verl.trainer.main_ppo --config-path=/mnt/task_runtime/verl/examples/sglang_multiturn/config --config-name=gsm8k_multiturn_grpo algorithm.adv_estimator=grpo data.train_batch_size=1024 data.max_prompt_length=128 data.filter_overlong_prompts=True data.truncation=error data.return_raw_chat=True data.filter_overlong_prompts_workers=40 actor_rollout_ref.model.path=Qwen/Qwen2.5-3B actor_rollout_ref.actor.optim.lr=1e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=256 actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=20 +actor_rollout_ref.ref.prob_in_loss=True +actor_rollout_ref.actor.prob_in_loss=True +actor_rollout_ref.actor.prob_in_loss_coeff=0.005 +actor_rollout_ref.actor.alpha=0.95 +actor_rollout_ref.ref.prob_in_reward_coeff=1.0 actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=80 actor_rollout_ref.actor.use_kl_loss=False actor_rollout_ref.actor.kl_loss_coef=0.0 actor_rollout_ref.actor.entropy_coeff=0.0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=40 actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=sglang actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=5 +actor_rollout_ref.rollout.per_turn_response_length=16 +actor_rollout_ref.rollout.max_code_lines=32 actor_rollout_ref.rollout.response_length=1024 algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=["console","wandb"]' trainer.project_name=rl-code-cpt-aug12 trainer.experiment_name=noentropy-prob-mean-nostd-format1-probloss0005-095alpha-ref-rerun trainer.n_gpus_per_node=8 trainer.nnodes=1 trainer.val_before_train=False trainer.save_freq=80 trainer.test_freq=-1 trainer.total_epochs=1 data.train_files=/root/data/sync_code/train.parquet data.val_files=/root/data/sync_code/test.parquet actor_rollout_ref.rollout.multi_turn.interaction_config_path=/mnt/task_runtime/verl/examples/sglang_multiturn/config/interaction_config/gsm8k_interaction_config.yaml actor_rollout_ref.rollout.multi_turn.max_user_turns=1
2025-08-12 21:08:44,298	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(TaskRunner pid=1380083)[0m TaskRunner hostname: bolt-fh6fg7ukdn-p3559ddgtm, PID: 1380083
[36m(TaskRunner pid=1380083)[0m {'actor_rollout_ref': {'actor': {'alpha': 0.95,
[36m(TaskRunner pid=1380083)[0m                                  'checkpoint': {'load_contents': ['hf_model',
[36m(TaskRunner pid=1380083)[0m                                                                   'model',
[36m(TaskRunner pid=1380083)[0m                                                                   'optimizer',
[36m(TaskRunner pid=1380083)[0m                                                                   'extra'],
[36m(TaskRunner pid=1380083)[0m                                                 'save_contents': ['hf_model',
[36m(TaskRunner pid=1380083)[0m                                                                   'model',
[36m(TaskRunner pid=1380083)[0m                                                                   'optimizer',
[36m(TaskRunner pid=1380083)[0m                                                                   'extra']},
[36m(TaskRunner pid=1380083)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=1380083)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=1380083)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=1380083)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=1380083)[0m                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=1380083)[0m                                  'entropy_coeff': 0.0,
[36m(TaskRunner pid=1380083)[0m                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=1380083)[0m                                  'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1380083)[0m                                                  'fsdp_size': -1,
[36m(TaskRunner pid=1380083)[0m                                                  'offload_policy': False,
[36m(TaskRunner pid=1380083)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=1380083)[0m                                                  'param_offload': False,
[36m(TaskRunner pid=1380083)[0m                                                  'reshard_after_forward': True,
[36m(TaskRunner pid=1380083)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1380083)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=1380083)[0m                                  'kl_loss_coef': 0.0,
[36m(TaskRunner pid=1380083)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=1380083)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1380083)[0m                                  'optim': {'lr': 1e-06,
[36m(TaskRunner pid=1380083)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=1380083)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1380083)[0m                                            'min_lr_ratio': 0.0,
[36m(TaskRunner pid=1380083)[0m                                            'num_cycles': 0.5,
[36m(TaskRunner pid=1380083)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=1380083)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=1380083)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=1380083)[0m                                  'policy_loss': {'clip_cov_lb': 1.0,
[36m(TaskRunner pid=1380083)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(TaskRunner pid=1380083)[0m                                                  'clip_cov_ub': 5.0,
[36m(TaskRunner pid=1380083)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(TaskRunner pid=1380083)[0m                                                  'loss_mode': 'vanilla',
[36m(TaskRunner pid=1380083)[0m                                                  'ppo_kl_coef': 0.1},
[36m(TaskRunner pid=1380083)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=1380083)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1380083)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1380083)[0m                                  'ppo_micro_batch_size_per_gpu': 20,
[36m(TaskRunner pid=1380083)[0m                                  'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=1380083)[0m                                  'prob_in_loss': True,
[36m(TaskRunner pid=1380083)[0m                                  'prob_in_loss_coeff': 0.005,
[36m(TaskRunner pid=1380083)[0m                                  'shuffle': False,
[36m(TaskRunner pid=1380083)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=1380083)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1380083)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=1380083)[0m                                  'use_kl_loss': False,
[36m(TaskRunner pid=1380083)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=1380083)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=1380083)[0m                        'model': {'custom_chat_template': None,
[36m(TaskRunner pid=1380083)[0m                                  'enable_activation_offload': False,
[36m(TaskRunner pid=1380083)[0m                                  'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1380083)[0m                                  'exclude_modules': None,
[36m(TaskRunner pid=1380083)[0m                                  'external_lib': None,
[36m(TaskRunner pid=1380083)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(TaskRunner pid=1380083)[0m                                  'lora_alpha': 16,
[36m(TaskRunner pid=1380083)[0m                                  'lora_rank': 0,
[36m(TaskRunner pid=1380083)[0m                                  'override_config': {},
[36m(TaskRunner pid=1380083)[0m                                  'path': 'Qwen/Qwen2.5-3B',
[36m(TaskRunner pid=1380083)[0m                                  'target_modules': 'all-linear',
[36m(TaskRunner pid=1380083)[0m                                  'trust_remote_code': False,
[36m(TaskRunner pid=1380083)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=1380083)[0m                                  'use_liger': False,
[36m(TaskRunner pid=1380083)[0m                                  'use_remove_padding': True,
[36m(TaskRunner pid=1380083)[0m                                  'use_shm': False},
[36m(TaskRunner pid=1380083)[0m                        'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1380083)[0m                                     'all_ranks': False,
[36m(TaskRunner pid=1380083)[0m                                     'discrete': False,
[36m(TaskRunner pid=1380083)[0m                                     'ranks': []},
[36m(TaskRunner pid=1380083)[0m                        'ref': {'entropy_checkpointing': False,
[36m(TaskRunner pid=1380083)[0m                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=1380083)[0m                                'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1380083)[0m                                                'param_offload': False,
[36m(TaskRunner pid=1380083)[0m                                                'reshard_after_forward': True,
[36m(TaskRunner pid=1380083)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1380083)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1380083)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1380083)[0m                                'log_prob_micro_batch_size_per_gpu': 80,
[36m(TaskRunner pid=1380083)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1380083)[0m                                'prob_in_loss': True,
[36m(TaskRunner pid=1380083)[0m                                'prob_in_reward_coeff': 1.0,
[36m(TaskRunner pid=1380083)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=1380083)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1380083)[0m                                'use_torch_compile': True},
[36m(TaskRunner pid=1380083)[0m                        'rollout': {'agent': {'agent_loop_config_path': None,
[36m(TaskRunner pid=1380083)[0m                                              'custom_async_server': {'name': None,
[36m(TaskRunner pid=1380083)[0m                                                                      'path': None},
[36m(TaskRunner pid=1380083)[0m                                              'num_workers': 8},
[36m(TaskRunner pid=1380083)[0m                                    'calculate_log_probs': False,
[36m(TaskRunner pid=1380083)[0m                                    'disable_log_stats': True,
[36m(TaskRunner pid=1380083)[0m                                    'do_sample': True,
[36m(TaskRunner pid=1380083)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=1380083)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=1380083)[0m                                    'enforce_eager': True,
[36m(TaskRunner pid=1380083)[0m                                    'engine_kwargs': {'sglang': {'attention_backend': None},
[36m(TaskRunner pid=1380083)[0m                                                      'vllm': {'disable_mm_preprocessor_cache': False,
[36m(TaskRunner pid=1380083)[0m                                                               'swap_space': None}},
[36m(TaskRunner pid=1380083)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=1380083)[0m                                    'gpu_memory_utilization': 0.8,
[36m(TaskRunner pid=1380083)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=1380083)[0m                                    'layered_summon': False,
[36m(TaskRunner pid=1380083)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=1380083)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1380083)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1380083)[0m                                    'log_prob_micro_batch_size_per_gpu': 40,
[36m(TaskRunner pid=1380083)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1380083)[0m                                    'max_code_lines': 32,
[36m(TaskRunner pid=1380083)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=1380083)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=1380083)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=1380083)[0m                                    'mode': 'sync',
[36m(TaskRunner pid=1380083)[0m                                    'multi_stage_wake_up': False,
[36m(TaskRunner pid=1380083)[0m                                    'multi_turn': {'completion_callback': None,
[36m(TaskRunner pid=1380083)[0m                                                   'enable': True,
[36m(TaskRunner pid=1380083)[0m                                                   'format': 'hermes',
[36m(TaskRunner pid=1380083)[0m                                                   'interaction_config_path': '/mnt/task_runtime/verl/examples/sglang_multiturn/config/interaction_config/gsm8k_interaction_config.yaml',
[36m(TaskRunner pid=1380083)[0m                                                   'max_assistant_turns': 100000,
[36m(TaskRunner pid=1380083)[0m                                                   'max_parallel_calls': 1,
[36m(TaskRunner pid=1380083)[0m                                                   'max_tool_response_length': 256,
[36m(TaskRunner pid=1380083)[0m                                                   'max_user_turns': 1,
[36m(TaskRunner pid=1380083)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(TaskRunner pid=1380083)[0m                                                   'tool_config_path': None,
[36m(TaskRunner pid=1380083)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(TaskRunner pid=1380083)[0m                                                   'use_inference_chat_template': False},
[36m(TaskRunner pid=1380083)[0m                                    'n': 5,
[36m(TaskRunner pid=1380083)[0m                                    'name': 'sglang',
[36m(TaskRunner pid=1380083)[0m                                    'per_turn_response_length': 16,
[36m(TaskRunner pid=1380083)[0m                                    'prompt_length': 128,
[36m(TaskRunner pid=1380083)[0m                                    'response_length': 1024,
[36m(TaskRunner pid=1380083)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=1380083)[0m                                    'tensor_model_parallel_size': 1,
[36m(TaskRunner pid=1380083)[0m                                    'top_k': -1,
[36m(TaskRunner pid=1380083)[0m                                    'top_p': 1,
[36m(TaskRunner pid=1380083)[0m                                    'trace': {'backend': None,
[36m(TaskRunner pid=1380083)[0m                                              'token2text': False},
[36m(TaskRunner pid=1380083)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(TaskRunner pid=1380083)[0m                                    'val_kwargs': {'do_sample': False,
[36m(TaskRunner pid=1380083)[0m                                                   'n': 1,
[36m(TaskRunner pid=1380083)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=1380083)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=1380083)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=1380083)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(TaskRunner pid=1380083)[0m                'adv_estimator': 'grpo',
[36m(TaskRunner pid=1380083)[0m                'gamma': 1.0,
[36m(TaskRunner pid=1380083)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(TaskRunner pid=1380083)[0m                            'horizon': 10000,
[36m(TaskRunner pid=1380083)[0m                            'kl_coef': 0.001,
[36m(TaskRunner pid=1380083)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=1380083)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=1380083)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=1380083)[0m                'lam': 1.0,
[36m(TaskRunner pid=1380083)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=1380083)[0m                'pf_ppo': {'_target_': 'verl.trainer.config.PFPPOConfig',
[36m(TaskRunner pid=1380083)[0m                           'reweight_method': 'pow',
[36m(TaskRunner pid=1380083)[0m                           'weight_pow': 2.0},
[36m(TaskRunner pid=1380083)[0m                'use_kl_in_reward': False,
[36m(TaskRunner pid=1380083)[0m                'use_pf_ppo': False},
[36m(TaskRunner pid=1380083)[0m  'critic': {'_target_': 'verl.trainer.config.FSDPCriticConfig',
[36m(TaskRunner pid=1380083)[0m             'checkpoint': {'load_contents': ['model', 'optimizer', 'extra'],
[36m(TaskRunner pid=1380083)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=1380083)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=1380083)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1380083)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=1380083)[0m             'forward_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1380083)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=1380083)[0m             'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1380083)[0m             'model': {'enable_activation_offload': False,
[36m(TaskRunner pid=1380083)[0m                       'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1380083)[0m                       'external_lib': None,
[36m(TaskRunner pid=1380083)[0m                       'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1380083)[0m                                       'fsdp_size': -1,
[36m(TaskRunner pid=1380083)[0m                                       'offload_policy': False,
[36m(TaskRunner pid=1380083)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=1380083)[0m                                       'param_offload': False,
[36m(TaskRunner pid=1380083)[0m                                       'reshard_after_forward': True,
[36m(TaskRunner pid=1380083)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1380083)[0m                       'lora_alpha': 16,
[36m(TaskRunner pid=1380083)[0m                       'lora_rank': 0,
[36m(TaskRunner pid=1380083)[0m                       'override_config': {},
[36m(TaskRunner pid=1380083)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(TaskRunner pid=1380083)[0m                       'target_modules': 'all-linear',
[36m(TaskRunner pid=1380083)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-3B',
[36m(TaskRunner pid=1380083)[0m                       'trust_remote_code': False,
[36m(TaskRunner pid=1380083)[0m                       'use_remove_padding': False,
[36m(TaskRunner pid=1380083)[0m                       'use_shm': False},
[36m(TaskRunner pid=1380083)[0m             'optim': {'lr': 1e-05,
[36m(TaskRunner pid=1380083)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1380083)[0m                       'min_lr_ratio': None,
[36m(TaskRunner pid=1380083)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=1380083)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=1380083)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=1380083)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=1380083)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1380083)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1380083)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1380083)[0m             'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=1380083)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1380083)[0m                          'all_ranks': False,
[36m(TaskRunner pid=1380083)[0m                          'discrete': False,
[36m(TaskRunner pid=1380083)[0m                          'ranks': []},
[36m(TaskRunner pid=1380083)[0m             'rollout_n': 5,
[36m(TaskRunner pid=1380083)[0m             'shuffle': False,
[36m(TaskRunner pid=1380083)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=1380083)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1380083)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=1380083)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=1380083)[0m  'data': {'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=1380083)[0m           'datagen': {'name': None, 'path': None},
[36m(TaskRunner pid=1380083)[0m           'dataloader_num_workers': 8,
[36m(TaskRunner pid=1380083)[0m           'filter_overlong_prompts': True,
[36m(TaskRunner pid=1380083)[0m           'filter_overlong_prompts_workers': 40,
[36m(TaskRunner pid=1380083)[0m           'image_key': 'images',
[36m(TaskRunner pid=1380083)[0m           'max_prompt_length': 128,
[36m(TaskRunner pid=1380083)[0m           'max_response_length': 1024,
[36m(TaskRunner pid=1380083)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=1380083)[0m           'return_full_prompt': False,
[36m(TaskRunner pid=1380083)[0m           'return_multi_modal_inputs': True,
[36m(TaskRunner pid=1380083)[0m           'return_raw_chat': True,
[36m(TaskRunner pid=1380083)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=1380083)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=1380083)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(TaskRunner pid=1380083)[0m           'shuffle': True,
[36m(TaskRunner pid=1380083)[0m           'tokenizer': None,
[36m(TaskRunner pid=1380083)[0m           'train_batch_size': 1024,
[36m(TaskRunner pid=1380083)[0m           'train_files': '/root/data/sync_code/train.parquet',
[36m(TaskRunner pid=1380083)[0m           'truncation': 'error',
[36m(TaskRunner pid=1380083)[0m           'trust_remote_code': False,
[36m(TaskRunner pid=1380083)[0m           'use_shm': False,
[36m(TaskRunner pid=1380083)[0m           'val_batch_size': None,
[36m(TaskRunner pid=1380083)[0m           'val_files': '/root/data/sync_code/test.parquet',
[36m(TaskRunner pid=1380083)[0m           'validation_shuffle': False,
[36m(TaskRunner pid=1380083)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=1380083)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(TaskRunner pid=1380083)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=1380083)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1380083)[0m                   'launch_reward_fn_async': False,
[36m(TaskRunner pid=1380083)[0m                   'max_length': None,
[36m(TaskRunner pid=1380083)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=1380083)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1380083)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=1380083)[0m                             'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1380083)[0m                                             'fsdp_size': -1,
[36m(TaskRunner pid=1380083)[0m                                             'param_offload': False,
[36m(TaskRunner pid=1380083)[0m                                             'reshard_after_forward': True,
[36m(TaskRunner pid=1380083)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1380083)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-3B',
[36m(TaskRunner pid=1380083)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=1380083)[0m                             'trust_remote_code': False,
[36m(TaskRunner pid=1380083)[0m                             'use_fused_kernels': False,
[36m(TaskRunner pid=1380083)[0m                             'use_remove_padding': False,
[36m(TaskRunner pid=1380083)[0m                             'use_shm': False},
[36m(TaskRunner pid=1380083)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1380083)[0m                                'all_ranks': False,
[36m(TaskRunner pid=1380083)[0m                                'discrete': False,
[36m(TaskRunner pid=1380083)[0m                                'ranks': []},
[36m(TaskRunner pid=1380083)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=1380083)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(TaskRunner pid=1380083)[0m                                      'memory_limit_mb': 1024,
[36m(TaskRunner pid=1380083)[0m                                      'url': None},
[36m(TaskRunner pid=1380083)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=1380083)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1380083)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=1380083)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=1380083)[0m              'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=1380083)[0m                                            'cuda-memory-usage': 'true',
[36m(TaskRunner pid=1380083)[0m                                            'trace': 'cuda,nvtx,cublas,ucx'},
[36m(TaskRunner pid=1380083)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=1380083)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=1380083)[0m              'default_local_dir': '/mnt/task_wrapper/user_output/artifacts/checkpoints/rl-code-cpt-aug12/noentropy-prob-mean-nostd-format1-probloss0005-095alpha-ref-rerun',
[36m(TaskRunner pid=1380083)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=1380083)[0m              'device': 'cuda',
[36m(TaskRunner pid=1380083)[0m              'esi_redundant_time': 0,
[36m(TaskRunner pid=1380083)[0m              'experiment_name': 'noentropy-prob-mean-nostd-format1-probloss0005-095alpha-ref-rerun',
[36m(TaskRunner pid=1380083)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=1380083)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=1380083)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=1380083)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=1380083)[0m              'n_gpus_per_node': 8,
[36m(TaskRunner pid=1380083)[0m              'nnodes': 1,
[36m(TaskRunner pid=1380083)[0m              'npu_profile': {'options': {'analysis': True,
[36m(TaskRunner pid=1380083)[0m                                          'level': 'level1',
[36m(TaskRunner pid=1380083)[0m                                          'record_shapes': False,
[36m(TaskRunner pid=1380083)[0m                                          'save_path': './profiler_data',
[36m(TaskRunner pid=1380083)[0m                                          'with_cpu': True,
[36m(TaskRunner pid=1380083)[0m                                          'with_memory': False,
[36m(TaskRunner pid=1380083)[0m                                          'with_module': False,
[36m(TaskRunner pid=1380083)[0m                                          'with_npu': True,
[36m(TaskRunner pid=1380083)[0m                                          'with_stack': False}},
[36m(TaskRunner pid=1380083)[0m              'profile_steps': None,
[36m(TaskRunner pid=1380083)[0m              'project_name': 'rl-code-cpt-aug12',
[36m(TaskRunner pid=1380083)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=1380083)[0m              'resume_from_path': None,
[36m(TaskRunner pid=1380083)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=1380083)[0m              'rollout_data_dir': None,
[36m(TaskRunner pid=1380083)[0m              'save_freq': 80,
[36m(TaskRunner pid=1380083)[0m              'test_freq': -1,
[36m(TaskRunner pid=1380083)[0m              'total_epochs': 1,
[36m(TaskRunner pid=1380083)[0m              'total_training_steps': None,
[36m(TaskRunner pid=1380083)[0m              'use_legacy_worker_impl': 'auto',
[36m(TaskRunner pid=1380083)[0m              'val_before_train': False,
[36m(TaskRunner pid=1380083)[0m              'val_only': False,
[36m(TaskRunner pid=1380083)[0m              'validation_data_dir': None,
[36m(TaskRunner pid=1380083)[0m              'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(TaskRunner pid=1380083)[0m                                        'capture-range-end': None,
[36m(TaskRunner pid=1380083)[0m                                        'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=1380083)[0m                                        'cuda-memory-usage': 'true',
[36m(TaskRunner pid=1380083)[0m                                        'kill': 'none',
[36m(TaskRunner pid=1380083)[0m                                        'trace': 'cuda,nvtx,cublas,ucx'}}}
[36m(TaskRunner pid=1380083)[0m 2025-08-12 21:08:51.024682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(TaskRunner pid=1380083)[0m 2025-08-12 21:08:51.035822: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(TaskRunner pid=1380083)[0m 2025-08-12 21:08:51.038870: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(TaskRunner pid=1380083)[0m 2025-08-12 21:08:51.047396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(TaskRunner pid=1380083)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(TaskRunner pid=1380083)[0m 2025-08-12 21:08:51.931229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[36m(TaskRunner pid=1380083)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=1380083)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1380083)[0m WARNING:2025-08-12 21:08:56,295:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   0%|          | 0/629183 [00:00<?, ? examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   0%|          | 1000/629183 [00:01<12:14, 855.36 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   0%|          | 3000/629183 [00:01<03:33, 2928.36 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   1%|          | 5000/629183 [00:01<02:03, 5061.56 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   1%|â–         | 8000/629183 [00:01<01:10, 8859.05 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   2%|â–         | 11000/629183 [00:01<00:49, 12391.71 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   2%|â–         | 14000/629183 [00:01<00:38, 15887.02 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   3%|â–Ž         | 19000/629183 [00:01<00:26, 23305.42 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   4%|â–         | 24000/629183 [00:01<00:20, 29436.43 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   5%|â–         | 29000/629183 [00:02<00:17, 33867.14 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   6%|â–Œ         | 37000/629183 [00:02<00:13, 44357.48 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   7%|â–‹         | 44000/629183 [00:02<00:11, 50232.29 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):   8%|â–Š         | 50000/629183 [00:02<00:11, 51719.47 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  10%|â–‰         | 60000/629183 [00:02<00:08, 63367.34 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  11%|â–ˆ         | 69000/629183 [00:02<00:08, 68997.48 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  12%|â–ˆâ–        | 78000/629183 [00:02<00:07, 71752.81 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  14%|â–ˆâ–        | 89000/629183 [00:02<00:06, 79981.29 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  16%|â–ˆâ–Œ        | 101000/629183 [00:02<00:06, 87759.54 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  18%|â–ˆâ–Š        | 112000/629183 [00:03<00:05, 91032.90 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  20%|â–ˆâ–ˆ        | 126000/629183 [00:03<00:04, 101602.85 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  22%|â–ˆâ–ˆâ–       | 140000/629183 [00:03<00:04, 108636.35 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  24%|â–ˆâ–ˆâ–       | 152000/629183 [00:03<00:04, 104246.10 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  27%|â–ˆâ–ˆâ–‹       | 167730/629183 [00:03<00:04, 108942.68 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  30%|â–ˆâ–ˆâ–‰       | 188460/629183 [00:03<00:03, 117273.13 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 209460/629183 [00:03<00:03, 133380.38 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  36%|â–ˆâ–ˆâ–ˆâ–‹      | 228920/629183 [00:03<00:02, 142522.01 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  39%|â–ˆâ–ˆâ–ˆâ–Š      | 243650/629183 [00:04<00:02, 134211.55 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 257650/629183 [00:04<00:02, 128108.40 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 273110/629183 [00:04<00:02, 133381.47 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 290110/629183 [00:04<00:02, 139949.28 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 304570/629183 [00:04<00:02, 136336.99 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 318570/629183 [00:04<00:02, 132793.19 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 336300/629183 [00:04<00:02, 144130.09 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 351760/629183 [00:04<00:02, 132057.25 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 367490/629183 [00:04<00:01, 137817.52 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 381950/629183 [00:05<00:01, 125791.24 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 409950/629183 [00:05<00:01, 164715.90 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 427410/629183 [00:05<00:01, 149209.90 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 443410/629183 [00:05<00:01, 145265.57 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 459140/629183 [00:05<00:01, 144855.11 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 474600/629183 [00:05<00:01, 141613.93 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 489060/629183 [00:05<00:01, 138181.26 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 503060/629183 [00:05<00:00, 129481.15 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 516519/629183 [00:06<00:00, 127814.34 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 530248/629183 [00:06<00:00, 114199.32 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 542248/629183 [00:06<00:00, 106495.14 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 553977/629183 [00:06<00:00, 105481.62 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 565435/629183 [00:06<00:00, 99750.80 examples/s] 
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 576435/629183 [00:06<00:00, 93447.55 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 586164/629183 [00:06<00:00, 90891.57 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 595622/629183 [00:06<00:00, 82917.17 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 604351/629183 [00:07<00:00, 73624.55 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 612809/629183 [00:07<00:00, 67762.96 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 620267/629183 [00:07<00:00, 54914.11 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 626725/629183 [00:07<00:00, 45349.10 examples/s]
[36m(TaskRunner pid=1380083)[0m dataset len: 624633
[36m(TaskRunner pid=1380083)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=40): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 629183/629183 [00:08<00:00, 77064.76 examples/s]
[36m(TaskRunner pid=1380083)[0m num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.
[36m(TaskRunner pid=1380083)[0m WARNING:2025-08-12 21:09:04,918:num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.
[36m(TaskRunner pid=1380083)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1380083)[0m WARNING:2025-08-12 21:09:04,919:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  10%|â–ˆ         | 1/10 [00:00<00:05,  1.54 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:02,  3.02 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:00<00:01,  4.34 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:00<00:01,  5.29 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:01<00:00,  5.66 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:01<00:00,  6.48 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:01<00:00,  7.78 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:01<00:00,  8.03 examples/s]
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  8.39 examples/s]
[36m(TaskRunner pid=1380083)[0m dataset len: 10
[36m(TaskRunner pid=1380083)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=1380083)[0m Size of train dataloader: 609, Size of val dataloader: 1
[36m(TaskRunner pid=1380083)[0m Total training steps: 609
[36m(TaskRunner pid=1380083)[0m colocated worker base class <class 'verl.single_controller.base.worker.Worker'>
[36m(TaskRunner pid=1380083)[0m Filter (num_proc=10): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.40 examples/s]
[36m(TaskRunner pid=1380083)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1380083)[0m WARNING:2025-08-12 21:09:07,647:Waiting for register center actor YLV7Xk_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(pid=1392056)[0m 2025-08-12 21:09:13.462334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(pid=1392056)[0m 2025-08-12 21:09:13.475444: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(pid=1392056)[0m 2025-08-12 21:09:13.479422: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(pid=1392056)[0m 2025-08-12 21:09:13.489140: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(pid=1392056)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(pid=1392056)[0m 2025-08-12 21:09:14.388681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[36m(pid=1393529)[0m 2025-08-12 21:09:25.444205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(pid=1393529)[0m 2025-08-12 21:09:25.457102: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(pid=1393529)[0m 2025-08-12 21:09:25.461059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(pid=1393529)[0m 2025-08-12 21:09:25.470798: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(pid=1393529)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(pid=1393529)[0m 2025-08-12 21:09:26.380060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[36m(pid=1393525)[0m 2025-08-12 21:09:27.161982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(pid=1393525)[0m 2025-08-12 21:09:27.175087: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(pid=1393525)[0m 2025-08-12 21:09:27.179057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(pid=1393525)[0m 2025-08-12 21:09:27.189134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(pid=1393525)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(WorkerDict pid=1393526)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(pid=1393531)[0m 2025-08-12 21:09:28.551000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 6x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=1393525)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(WorkerDict pid=1393525)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.20it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.17it/s]
[36m(WorkerDict pid=1393525)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1393525)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=1392056)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=1392056)[0m   "architectures": [
[36m(WorkerDict pid=1392056)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=1392056)[0m   ],
[36m(WorkerDict pid=1392056)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=1392056)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=1392056)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=1392056)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=1392056)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=1392056)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=1392056)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=1392056)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=1392056)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=1392056)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=1392056)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=1392056)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=1392056)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=1392056)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=1392056)[0m   "rope_scaling": null,
[36m(WorkerDict pid=1392056)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=1392056)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=1392056)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=1392056)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=1392056)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=1392056)[0m   "use_cache": true,
[36m(WorkerDict pid=1392056)[0m   "use_mrope": false,
[36m(WorkerDict pid=1392056)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=1392056)[0m   "vocab_size": 151936
[36m(WorkerDict pid=1392056)[0m }
[36m(WorkerDict pid=1392056)[0m 
[36m(pid=1393531)[0m 2025-08-12 21:09:27.488040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered[32m [repeated 5x across cluster][0m
[36m(pid=1393531)[0m 2025-08-12 21:09:27.502456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered[32m [repeated 5x across cluster][0m
[36m(pid=1393531)[0m 2025-08-12 21:09:27.506655: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered[32m [repeated 5x across cluster][0m
[36m(pid=1393531)[0m 2025-08-12 21:09:27.517559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 5x across cluster][0m
[36m(pid=1393531)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 5x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Qwen2ForCausalLM contains 3.09B parameters
[36m(WorkerDict pid=1392056)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ee691fe9d80>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ee691fe9c60>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=1392056)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=1392056)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=1392056)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=1392056)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1393526)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=1392056)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.41it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.38it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=1392056)[0m   "architectures": [
[36m(WorkerDict pid=1392056)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=1392056)[0m   ],
[36m(WorkerDict pid=1392056)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=1392056)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=1392056)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=1392056)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=1392056)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=1392056)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=1392056)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=1392056)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=1392056)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=1392056)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=1392056)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=1392056)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=1392056)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=1392056)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=1392056)[0m   "rope_scaling": null,
[36m(WorkerDict pid=1392056)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=1392056)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=1392056)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=1392056)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=1392056)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=1392056)[0m   "use_cache": true,
[36m(WorkerDict pid=1392056)[0m   "use_mrope": false,
[36m(WorkerDict pid=1392056)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=1392056)[0m   "vocab_size": 151936
[36m(WorkerDict pid=1392056)[0m }
[36m(WorkerDict pid=1392056)[0m 
[36m(WorkerDict pid=1393525)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.70s/it]
[36m(WorkerDict pid=1393530)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1393530)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 8x across cluster][0m
[36m(WorkerDict pid=1393525)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.73s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.88s/it]
[36m(WorkerDict pid=1393526)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.75s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.90s/it]
[36m(WorkerDict pid=1393525)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1393525)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=1393526)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1393526)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=1392056)[0m Qwen2ForCausalLM contains 3.09B parameters
[36m(WorkerDict pid=1392056)[0m wrap_policy: functools.partial(<function _or_policy at 0x7ee691fe9d80>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7ee691fe9c60>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=1392056)[0m Total steps: 609, num_warmup_steps: 0
[36m(WorkerDict pid=1392056)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=1392056)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=1392056)[0m   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=12.86 GB):   0%|          | 0/23 [00:00<?, ?it/s]
[36m(WorkerDict pid=1393530)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.71s/it][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1393528)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.76s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.91s/it][32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Capturing batches (avail_mem=12.86 GB):   4%|â–         | 1/23 [00:00<00:18,  1.20it/s]Capturing batches (avail_mem=12.64 GB):   4%|â–         | 1/23 [00:00<00:18,  1.20it/s]
[36m(WorkerDict pid=1392056)[0m Capturing batches (avail_mem=12.64 GB):   9%|â–Š         | 2/23 [00:01<00:16,  1.29it/s]Capturing batches (avail_mem=12.52 GB):   9%|â–Š         | 2/23 [00:01<00:16,  1.29it/s]
[36m(WorkerDict pid=1393529)[0m   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=12.92 GB):   0%|          | 0/23 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Capturing batches (avail_mem=11.89 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:05<00:06,  1.90it/s]Capturing batches (avail_mem=11.82 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:05<00:06,  1.90it/s][32m [repeated 59x across cluster][0m
[36m(WorkerDict pid=1392056)[0m Capturing batches (avail_mem=11.48 GB):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20/23 [00:10<00:01,  1.98it/s]Capturing batches (avail_mem=11.48 GB):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20/23 [00:10<00:01,  1.98it/s][32m [repeated 77x across cluster][0m
[36m(WorkerDict pid=1393527)[0m Capturing batches (avail_mem=11.43 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:09<00:00,  2.26it/s]Capturing batches (avail_mem=11.42 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:09<00:00,  2.26it/s]
[36m(WorkerDict pid=1393527)[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1393527)[0m   warnings.warn(
[36m(TaskRunner pid=1380083)[0m wandb: Currently logged in as: shenaozhang (shenaoz) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(WorkerDict pid=1393526)[0m Capturing batches (avail_mem=11.44 GB):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20/23 [00:11<00:01,  1.72it/s]Capturing batches (avail_mem=11.43 GB):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20/23 [00:11<00:01,  1.72it/s][32m [repeated 22x across cluster][0m
[36m(WorkerDict pid=1393526)[0m Capturing batches (avail_mem=11.41 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.77it/s]Capturing batches (avail_mem=11.41 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.70it/s][32m [repeated 23x across cluster][0m
[36m(TaskRunner pid=1380083)[0m wandb: Tracking run with wandb version 0.21.1
[36m(TaskRunner pid=1380083)[0m wandb: Run data is saved locally in /mnt/task_runtime/verl/wandb/run-20250812_211104-fny8s6g2
[36m(TaskRunner pid=1380083)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(TaskRunner pid=1380083)[0m wandb: Syncing run noentropy-prob-mean-nostd-format1-probloss0005-095alpha-ref-rerun
[36m(TaskRunner pid=1380083)[0m wandb: â­ï¸ View project at https://wandb.ai/shenaoz/rl-code-cpt-aug12
[36m(TaskRunner pid=1380083)[0m wandb: ðŸš€ View run at https://wandb.ai/shenaoz/rl-code-cpt-aug12/runs/fny8s6g2
[36m(TaskRunner pid=1380083)[0m Checkpoint tracker file does not exist: /mnt/task_wrapper/user_output/artifacts/checkpoints/rl-code-cpt-aug12/noentropy-prob-mean-nostd-format1-probloss0005-095alpha-ref-rerun/latest_checkpointed_iteration.txt
[36m(TaskRunner pid=1380083)[0m Training from scratch
[36m(WorkerDict pid=1393529)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1393529)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch[32m [repeated 6x across cluster][0m
[36m(TaskRunner pid=1380083)[0m Training Progress:   0%|          | 0/609 [00:00<?, ?it/s]
[36m(WorkerDict pid=1392056)[0m /mnt/task_runtime/verl/verl/workers/rollout/sglang_rollout/utils.py:49: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
[36m(WorkerDict pid=1392056)[0m   tensor_data = torch.ByteTensor(np.frombuffer(serialized_data, dtype=np.uint8)).to(device)
[36m(WorkerDict pid=1393526)[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1393526)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1393525)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=1392056)[0m tid1:  [7.172344385075746e-10, 0.802150547504425, 0.0005138124106451869, 0.9971145391464233, 0.5811648368835449, 0.13872553408145905] endtid1
[36m(WorkerDict pid=1392056)[0m tid6:  [0.9681228399276733, 1.3722888070333283e-05, 0.12911836802959442] endtid6
[36m(WorkerDict pid=1393527)[0m NCCL version 2.21.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1393525)[0m tid1:  [7.048482630889197e-11, 0.8136659860610962, 0.004020857624709606, 0.9952942132949829, 0.8769663572311401, 0.19172754883766174] endtid1
[36m(WorkerDict pid=1393525)[0m tid6:  [0.028076600283384323, 0.6581217050552368, 0.9889888763427734] endtid6
[36m(WorkerDict pid=1393526)[0m tid1:  [1.1534374844135442e-10, 0.7136679887771606, 0.0028923831414431334, 0.9981287121772766, 0.760565459728241, 0.2512800097465515] endtid1
[36m(WorkerDict pid=1393526)[0m tid6:  [0.5757981538772583, 5.029941121392767e-07, 0.9854940176010132] endtid6
[36m(WorkerDict pid=1393528)[0m tid1:  [1.0233834450441154e-13, 0.49588263034820557, 0.955144464969635, 0.9970422983169556, 0.9959341883659363, 8.207433893403504e-06, 0.4962393343448639, 0.5071601271629333, 0.9245966076850891, 0.9644753932952881, 0.9954308867454529, 0.260298490524292] endtid1
[36m(WorkerDict pid=1393528)[0m tid6:  [0.00014676901628263295, 0.1094672828912735, 0.9463115930557251, 0.25885525345802307, 0.7987917065620422, 0.9183940291404724, 0.1797211766242981] endtid6
[36m(WorkerDict pid=1393527)[0m tid1:  [9.758383337499232e-13, 0.6486998796463013, 0.0012970471289008856, 0.9974873661994934, 0.8221853971481323, 0.2954213321208954] endtid1
[36m(WorkerDict pid=1393527)[0m tid6:  [0.051006246358156204, 0.0012492008972913027, 0.9866111874580383] endtid6
[36m(WorkerDict pid=1393529)[0m tid1:  [2.2845654187864106e-11, 0.9303103685379028, 0.9850655794143677, 0.9992011785507202, 0.0007081454386934638, 0.011296105571091175] endtid1
[36m(WorkerDict pid=1393529)[0m tid6:  [0.0045930929481983185, 0.020098498091101646, 0.8055834770202637] endtid6
[36m(WorkerDict pid=1393530)[0m tid1:  [1.3665970577392272e-09, 0.004074280150234699, 0.24642261862754822, 0.11933460086584091, 0.8760786652565002, 0.9018769264221191, 0.833627462387085, 0.9994108080863953, 0.9842767715454102, 0.9028218388557434, 0.9988486766815186, 0.9985247850418091, 0.9990658760070801, 0.9995080232620239, 0.3069353699684143, 0.9169202446937561, 0.9858700633049011, 0.997590184211731, 0.9990792274475098, 0.999733030796051, 0.9908921718597412, 0.9987019300460815, 0.9996910691261292, 0.997991681098938, 0.9988886117935181, 0.9996472001075745, 0.08972850441932678] endtid1
[36m(WorkerDict pid=1393530)[0m tid6:  [0.003492535324767232, 0.7242901921272278, 0.1962880641222, 0.5166996121406555] endtid6
[36m(WorkerDict pid=1393531)[0m tid1:  [7.62523288955208e-09, 0.0024981265887618065, 0.07340935617685318, 0.81069016456604, 0.031679075211286545, 0.006672517862170935, 0.6986532807350159, 0.008959198370575905] endtid1
[36m(WorkerDict pid=1393531)[0m tid6:  [3.1870909879216924e-05, 0.4529649019241333, 0.9893775582313538, 0.4970625042915344, 0.5087539553642273, 0.9866732954978943, 0.880729615688324, 0.8108880519866943, 0.9845621585845947, 0.9984829425811768, 0.9695031642913818, 0.8691133856773376, 0.9460048079490662, 0.9582593441009521] endtid6
[36m(WorkerDict pid=1392056)[0m tid1:  [8.134519099978199e-12, 0.5266464352607727, 0.8404926061630249, 0.9992221593856812, 0.4188457429409027, 0.32880091667175293, 0.19007627665996552] endtid1
[36m(WorkerDict pid=1392056)[0m tid6:  [1.7697564524965514e-09, 0.020503662526607513, 0.8661676645278931] endtid6
[36m(WorkerDict pid=1393525)[0m tid1:  [3.3485703099245256e-09, 0.11294279247522354, 0.24398598074913025, 0.7804915904998779, 0.6927299499511719, 0.8898952603340149, 0.4486279785633087, 0.7466134428977966, 0.8760854005813599, 0.999258279800415, 0.7028850317001343, 0.9990487098693848, 0.934792697429657, 0.03266492113471031] endtid1
[36m(WorkerDict pid=1393525)[0m tid6:  [0.008072130382061005, 0.042955249547958374, 0.08331183344125748, 0.8456447124481201, 0.5307294130325317] endtid6
[36m(WorkerDict pid=1393526)[0m tid1:  [2.0428796432270246e-09, 0.0014338531764224172, 0.7125961184501648, 0.07250956445932388] endtid1
[36m(WorkerDict pid=1393526)[0m tid6:  [1.01716714198119e-05, 0.06083528324961662, 0.607857882976532, 0.9057470560073853, 0.6787717938423157, 0.9179264307022095, 0.6890060901641846, 0.9545598030090332, 0.6435093283653259, 0.3637537658214569, 0.7941415905952454, 0.8348909020423889, 0.9879199266433716, 0.8994461297988892, 0.9558752775192261, 0.9419788718223572, 0.9410611391067505, 0.9242210984230042, 0.8412688970565796] endtid6
[36m(WorkerDict pid=1393528)[0m tid1:  [5.243762889184378e-12, 0.6025755405426025, 0.9569661617279053, 0.00017841313092503697, 0.8134394288063049, 0.0454283244907856, 0.6172842383384705] endtid1
[36m(WorkerDict pid=1393528)[0m tid6:  [4.072482440165004e-08, 0.07108622044324875, 0.8359872102737427] endtid6
[36m(WorkerDict pid=1393527)[0m tid1:  [2.0611194528896704e-08, 0.0051207710057497025, 0.16412562131881714, 0.9342686533927917, 0.997434139251709, 0.972069501876831, 0.9912097454071045, 0.6123976111412048, 0.02088805101811886] endtid1
[36m(WorkerDict pid=1393527)[0m tid6:  [0.00024029276391956955, 0.005281225778162479, 0.023121803998947144, 0.4808404743671417, 0.9868972897529602, 0.8369093537330627, 0.9696400165557861, 0.9837436676025391, 0.7622675895690918] endtid6
[36m(WorkerDict pid=1393529)[0m tid1:  [8.373729656341311e-07, 0.00012606150994542986, 0.0046412646770477295, 0.08991403877735138, 0.3443852663040161, 0.5732022523880005, 0.03747323900461197] endtid1
[36m(WorkerDict pid=1393529)[0m tid6:  [2.8864116757176816e-05, 0.026155101135373116, 0.941788375377655, 0.9472505450248718, 0.880279541015625, 0.8222701549530029, 0.9715245962142944, 0.987763524055481, 0.9877672791481018, 0.9425575733184814, 0.4178563058376312, 0.9806058406829834, 0.2953283488750458, 0.9306226968765259, 0.6820500493049622, 0.9214856624603271, 0.9114695191383362, 0.6653525233268738, 0.8049814105033875, 0.981698751449585, 0.8797155618667603, 0.9666227102279663, 0.9855241179466248, 0.30491530895233154] endtid6
[36m(WorkerDict pid=1393530)[0m tid1:  [3.6160971439436196e-10, 0.38491055369377136, 0.9810361266136169, 0.9973846673965454, 0.8141565322875977, 0.08717875927686691] endtid1
[36m(WorkerDict pid=1393530)[0m tid6:  [] endtid6
[36m(WorkerDict pid=1393531)[0m tid1:  [6.545377087552318e-12, 0.010807535611093044, 0.09221585839986801, 0.5993202924728394, 0.07843952625989914] endtid1
[36m(WorkerDict pid=1393531)[0m tid6:  [1.94288099919504e-06, 0.17220142483711243, 0.1302405744791031, 0.5892796516418457, 0.8861654996871948, 0.303844153881073] endtid6
