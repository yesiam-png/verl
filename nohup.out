+ export HYDRA_FULL_ERROR=1
+ HYDRA_FULL_ERROR=1
+ ulimit -n 65535
++ pwd
+ PROJECT_DIR=/mnt/task_runtime/verl
+ CONFIG_PATH=/mnt/task_runtime/verl/examples/sglang_multiturn/config
+ python3 -m verl.trainer.main_ppo --config-path=/mnt/task_runtime/verl/examples/sglang_multiturn/config --config-name=gsm8k_multiturn_grpo algorithm.adv_estimator=grpo data.train_batch_size=1024 data.max_prompt_length=128 data.filter_overlong_prompts=True data.truncation=error data.return_raw_chat=True data.filter_overlong_prompts_workers=40 actor_rollout_ref.model.path=/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b +actor_rollout_ref.actor.ntp_coeff=1.0 actor_rollout_ref.actor.optim.lr=2e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=256 +actor_rollout_ref.actor.ntp_mini_batch_size=512 actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=40 +actor_rollout_ref.actor.ntp_micro_batch_size_per_gpu=64 actor_rollout_ref.actor.use_kl_loss=False actor_rollout_ref.actor.kl_loss_coef=0.0 actor_rollout_ref.actor.entropy_coeff=0.0 actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=80 actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=80 actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=sglang actor_rollout_ref.rollout.gpu_memory_utilization=0.8 actor_rollout_ref.rollout.n=5 actor_rollout_ref.rollout.temperature=1.0 +actor_rollout_ref.rollout.per_turn_response_length=32 +actor_rollout_ref.rollout.max_code_lines=32 actor_rollout_ref.rollout.response_length=1024 algorithm.use_kl_in_reward=False trainer.critic_warmup=0 'trainer.logger=["console","wandb"]' trainer.project_name=em-new trainer.experiment_name=em-reslen32-60-120-penalty004-nosys trainer.n_gpus_per_node=8 trainer.nnodes=1 trainer.val_before_train=False trainer.save_freq=40 trainer.test_freq=-1 trainer.total_epochs=1 +trainer.q_steps=60 +trainer.ref_update_freq=120 data.train_files=/root/data/sync_code/train.parquet data.val_files=/root/data/sync_code/test.parquet actor_rollout_ref.rollout.multi_turn.interaction_config_path=/mnt/task_runtime/verl/examples/sglang_multiturn/config/interaction_config/gsm8k_interaction_config.yaml actor_rollout_ref.rollout.multi_turn.max_user_turns=1
2025-08-19 21:32:51,463	INFO worker.py:1918 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(TaskRunner pid=1129931)[0m TaskRunner hostname: bolt-mcd2umnbr9-t3t3k8znvj, PID: 1129931
[36m(TaskRunner pid=1129931)[0m {'actor_rollout_ref': {'actor': {'checkpoint': {'load_contents': ['hf_model',
[36m(TaskRunner pid=1129931)[0m                                                                   'model',
[36m(TaskRunner pid=1129931)[0m                                                                   'optimizer',
[36m(TaskRunner pid=1129931)[0m                                                                   'extra'],
[36m(TaskRunner pid=1129931)[0m                                                 'save_contents': ['hf_model',
[36m(TaskRunner pid=1129931)[0m                                                                   'model',
[36m(TaskRunner pid=1129931)[0m                                                                   'optimizer',
[36m(TaskRunner pid=1129931)[0m                                                                   'extra']},
[36m(TaskRunner pid=1129931)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=1129931)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=1129931)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=1129931)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=1129931)[0m                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=1129931)[0m                                  'entropy_coeff': 0.0,
[36m(TaskRunner pid=1129931)[0m                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=1129931)[0m                                  'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1129931)[0m                                                  'fsdp_size': -1,
[36m(TaskRunner pid=1129931)[0m                                                  'offload_policy': False,
[36m(TaskRunner pid=1129931)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=1129931)[0m                                                  'param_offload': False,
[36m(TaskRunner pid=1129931)[0m                                                  'reshard_after_forward': True,
[36m(TaskRunner pid=1129931)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1129931)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=1129931)[0m                                  'kl_loss_coef': 0.0,
[36m(TaskRunner pid=1129931)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=1129931)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1129931)[0m                                  'ntp_coeff': 1.0,
[36m(TaskRunner pid=1129931)[0m                                  'ntp_micro_batch_size_per_gpu': 64,
[36m(TaskRunner pid=1129931)[0m                                  'ntp_mini_batch_size': 512,
[36m(TaskRunner pid=1129931)[0m                                  'optim': {'lr': 2e-06,
[36m(TaskRunner pid=1129931)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=1129931)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1129931)[0m                                            'min_lr_ratio': 0.0,
[36m(TaskRunner pid=1129931)[0m                                            'num_cycles': 0.5,
[36m(TaskRunner pid=1129931)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=1129931)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=1129931)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=1129931)[0m                                  'policy_loss': {'clip_cov_lb': 1.0,
[36m(TaskRunner pid=1129931)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(TaskRunner pid=1129931)[0m                                                  'clip_cov_ub': 5.0,
[36m(TaskRunner pid=1129931)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(TaskRunner pid=1129931)[0m                                                  'loss_mode': 'vanilla',
[36m(TaskRunner pid=1129931)[0m                                                  'ppo_kl_coef': 0.1},
[36m(TaskRunner pid=1129931)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=1129931)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1129931)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1129931)[0m                                  'ppo_micro_batch_size_per_gpu': 40,
[36m(TaskRunner pid=1129931)[0m                                  'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=1129931)[0m                                  'shuffle': False,
[36m(TaskRunner pid=1129931)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=1129931)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1129931)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=1129931)[0m                                  'use_kl_loss': False,
[36m(TaskRunner pid=1129931)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=1129931)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=1129931)[0m                        'model': {'custom_chat_template': None,
[36m(TaskRunner pid=1129931)[0m                                  'enable_activation_offload': False,
[36m(TaskRunner pid=1129931)[0m                                  'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1129931)[0m                                  'exclude_modules': None,
[36m(TaskRunner pid=1129931)[0m                                  'external_lib': None,
[36m(TaskRunner pid=1129931)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(TaskRunner pid=1129931)[0m                                  'lora_alpha': 16,
[36m(TaskRunner pid=1129931)[0m                                  'lora_rank': 0,
[36m(TaskRunner pid=1129931)[0m                                  'override_config': {},
[36m(TaskRunner pid=1129931)[0m                                  'path': '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b',
[36m(TaskRunner pid=1129931)[0m                                  'target_modules': 'all-linear',
[36m(TaskRunner pid=1129931)[0m                                  'trust_remote_code': False,
[36m(TaskRunner pid=1129931)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=1129931)[0m                                  'use_liger': False,
[36m(TaskRunner pid=1129931)[0m                                  'use_remove_padding': True,
[36m(TaskRunner pid=1129931)[0m                                  'use_shm': False},
[36m(TaskRunner pid=1129931)[0m                        'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1129931)[0m                                     'all_ranks': False,
[36m(TaskRunner pid=1129931)[0m                                     'discrete': False,
[36m(TaskRunner pid=1129931)[0m                                     'ranks': []},
[36m(TaskRunner pid=1129931)[0m                        'ref': {'entropy_checkpointing': False,
[36m(TaskRunner pid=1129931)[0m                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=1129931)[0m                                'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1129931)[0m                                                'param_offload': False,
[36m(TaskRunner pid=1129931)[0m                                                'reshard_after_forward': True,
[36m(TaskRunner pid=1129931)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1129931)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1129931)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1129931)[0m                                'log_prob_micro_batch_size_per_gpu': 80,
[36m(TaskRunner pid=1129931)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1129931)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=1129931)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1129931)[0m                                'use_torch_compile': True},
[36m(TaskRunner pid=1129931)[0m                        'rollout': {'agent': {'agent_loop_config_path': None,
[36m(TaskRunner pid=1129931)[0m                                              'custom_async_server': {'name': None,
[36m(TaskRunner pid=1129931)[0m                                                                      'path': None},
[36m(TaskRunner pid=1129931)[0m                                              'num_workers': 8},
[36m(TaskRunner pid=1129931)[0m                                    'calculate_log_probs': False,
[36m(TaskRunner pid=1129931)[0m                                    'disable_log_stats': True,
[36m(TaskRunner pid=1129931)[0m                                    'do_sample': True,
[36m(TaskRunner pid=1129931)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=1129931)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=1129931)[0m                                    'enforce_eager': True,
[36m(TaskRunner pid=1129931)[0m                                    'engine_kwargs': {'sglang': {'attention_backend': None},
[36m(TaskRunner pid=1129931)[0m                                                      'vllm': {'disable_mm_preprocessor_cache': False,
[36m(TaskRunner pid=1129931)[0m                                                               'swap_space': None}},
[36m(TaskRunner pid=1129931)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=1129931)[0m                                    'gpu_memory_utilization': 0.8,
[36m(TaskRunner pid=1129931)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=1129931)[0m                                    'layered_summon': False,
[36m(TaskRunner pid=1129931)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=1129931)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1129931)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1129931)[0m                                    'log_prob_micro_batch_size_per_gpu': 80,
[36m(TaskRunner pid=1129931)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1129931)[0m                                    'max_code_lines': 32,
[36m(TaskRunner pid=1129931)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=1129931)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=1129931)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=1129931)[0m                                    'mode': 'sync',
[36m(TaskRunner pid=1129931)[0m                                    'multi_stage_wake_up': False,
[36m(TaskRunner pid=1129931)[0m                                    'multi_turn': {'completion_callback': None,
[36m(TaskRunner pid=1129931)[0m                                                   'enable': True,
[36m(TaskRunner pid=1129931)[0m                                                   'format': 'hermes',
[36m(TaskRunner pid=1129931)[0m                                                   'interaction_config_path': '/mnt/task_runtime/verl/examples/sglang_multiturn/config/interaction_config/gsm8k_interaction_config.yaml',
[36m(TaskRunner pid=1129931)[0m                                                   'max_assistant_turns': 100000,
[36m(TaskRunner pid=1129931)[0m                                                   'max_parallel_calls': 1,
[36m(TaskRunner pid=1129931)[0m                                                   'max_tool_response_length': 256,
[36m(TaskRunner pid=1129931)[0m                                                   'max_user_turns': 1,
[36m(TaskRunner pid=1129931)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(TaskRunner pid=1129931)[0m                                                   'tool_config_path': None,
[36m(TaskRunner pid=1129931)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(TaskRunner pid=1129931)[0m                                                   'use_inference_chat_template': False},
[36m(TaskRunner pid=1129931)[0m                                    'n': 5,
[36m(TaskRunner pid=1129931)[0m                                    'name': 'sglang',
[36m(TaskRunner pid=1129931)[0m                                    'per_turn_response_length': 32,
[36m(TaskRunner pid=1129931)[0m                                    'prompt_length': 128,
[36m(TaskRunner pid=1129931)[0m                                    'response_length': 1024,
[36m(TaskRunner pid=1129931)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=1129931)[0m                                    'tensor_model_parallel_size': 1,
[36m(TaskRunner pid=1129931)[0m                                    'top_k': -1,
[36m(TaskRunner pid=1129931)[0m                                    'top_p': 1,
[36m(TaskRunner pid=1129931)[0m                                    'trace': {'backend': None,
[36m(TaskRunner pid=1129931)[0m                                              'token2text': False},
[36m(TaskRunner pid=1129931)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(TaskRunner pid=1129931)[0m                                    'val_kwargs': {'do_sample': False,
[36m(TaskRunner pid=1129931)[0m                                                   'n': 1,
[36m(TaskRunner pid=1129931)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=1129931)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=1129931)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=1129931)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(TaskRunner pid=1129931)[0m                'adv_estimator': 'grpo',
[36m(TaskRunner pid=1129931)[0m                'gamma': 1.0,
[36m(TaskRunner pid=1129931)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(TaskRunner pid=1129931)[0m                            'horizon': 10000,
[36m(TaskRunner pid=1129931)[0m                            'kl_coef': 0.001,
[36m(TaskRunner pid=1129931)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=1129931)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=1129931)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=1129931)[0m                'lam': 1.0,
[36m(TaskRunner pid=1129931)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=1129931)[0m                'pf_ppo': {'_target_': 'verl.trainer.config.PFPPOConfig',
[36m(TaskRunner pid=1129931)[0m                           'reweight_method': 'pow',
[36m(TaskRunner pid=1129931)[0m                           'weight_pow': 2.0},
[36m(TaskRunner pid=1129931)[0m                'use_kl_in_reward': False,
[36m(TaskRunner pid=1129931)[0m                'use_pf_ppo': False},
[36m(TaskRunner pid=1129931)[0m  'critic': {'_target_': 'verl.trainer.config.FSDPCriticConfig',
[36m(TaskRunner pid=1129931)[0m             'checkpoint': {'load_contents': ['model', 'optimizer', 'extra'],
[36m(TaskRunner pid=1129931)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=1129931)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=1129931)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1129931)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=1129931)[0m             'forward_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1129931)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=1129931)[0m             'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1129931)[0m             'model': {'enable_activation_offload': False,
[36m(TaskRunner pid=1129931)[0m                       'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1129931)[0m                       'external_lib': None,
[36m(TaskRunner pid=1129931)[0m                       'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1129931)[0m                                       'fsdp_size': -1,
[36m(TaskRunner pid=1129931)[0m                                       'offload_policy': False,
[36m(TaskRunner pid=1129931)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=1129931)[0m                                       'param_offload': False,
[36m(TaskRunner pid=1129931)[0m                                       'reshard_after_forward': True,
[36m(TaskRunner pid=1129931)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1129931)[0m                       'lora_alpha': 16,
[36m(TaskRunner pid=1129931)[0m                       'lora_rank': 0,
[36m(TaskRunner pid=1129931)[0m                       'override_config': {},
[36m(TaskRunner pid=1129931)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(TaskRunner pid=1129931)[0m                       'target_modules': 'all-linear',
[36m(TaskRunner pid=1129931)[0m                       'tokenizer_path': '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b',
[36m(TaskRunner pid=1129931)[0m                       'trust_remote_code': False,
[36m(TaskRunner pid=1129931)[0m                       'use_remove_padding': False,
[36m(TaskRunner pid=1129931)[0m                       'use_shm': False},
[36m(TaskRunner pid=1129931)[0m             'optim': {'lr': 1e-05,
[36m(TaskRunner pid=1129931)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1129931)[0m                       'min_lr_ratio': None,
[36m(TaskRunner pid=1129931)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=1129931)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=1129931)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=1129931)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=1129931)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1129931)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1129931)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1129931)[0m             'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=1129931)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1129931)[0m                          'all_ranks': False,
[36m(TaskRunner pid=1129931)[0m                          'discrete': False,
[36m(TaskRunner pid=1129931)[0m                          'ranks': []},
[36m(TaskRunner pid=1129931)[0m             'rollout_n': 5,
[36m(TaskRunner pid=1129931)[0m             'shuffle': False,
[36m(TaskRunner pid=1129931)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=1129931)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1129931)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=1129931)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=1129931)[0m  'data': {'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=1129931)[0m           'datagen': {'name': None, 'path': None},
[36m(TaskRunner pid=1129931)[0m           'dataloader_num_workers': 8,
[36m(TaskRunner pid=1129931)[0m           'filter_overlong_prompts': True,
[36m(TaskRunner pid=1129931)[0m           'filter_overlong_prompts_workers': 40,
[36m(TaskRunner pid=1129931)[0m           'image_key': 'images',
[36m(TaskRunner pid=1129931)[0m           'max_prompt_length': 128,
[36m(TaskRunner pid=1129931)[0m           'max_response_length': 1024,
[36m(TaskRunner pid=1129931)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=1129931)[0m           'return_full_prompt': False,
[36m(TaskRunner pid=1129931)[0m           'return_multi_modal_inputs': True,
[36m(TaskRunner pid=1129931)[0m           'return_raw_chat': True,
[36m(TaskRunner pid=1129931)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=1129931)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=1129931)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(TaskRunner pid=1129931)[0m           'shuffle': True,
[36m(TaskRunner pid=1129931)[0m           'tokenizer': None,
[36m(TaskRunner pid=1129931)[0m           'train_batch_size': 1024,
[36m(TaskRunner pid=1129931)[0m           'train_files': '/root/data/sync_code/train.parquet',
[36m(TaskRunner pid=1129931)[0m           'truncation': 'error',
[36m(TaskRunner pid=1129931)[0m           'trust_remote_code': False,
[36m(TaskRunner pid=1129931)[0m           'use_shm': False,
[36m(TaskRunner pid=1129931)[0m           'val_batch_size': None,
[36m(TaskRunner pid=1129931)[0m           'val_files': '/root/data/sync_code/test.parquet',
[36m(TaskRunner pid=1129931)[0m           'validation_shuffle': False,
[36m(TaskRunner pid=1129931)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=1129931)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(TaskRunner pid=1129931)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=1129931)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1129931)[0m                   'launch_reward_fn_async': False,
[36m(TaskRunner pid=1129931)[0m                   'max_length': None,
[36m(TaskRunner pid=1129931)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=1129931)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1129931)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=1129931)[0m                             'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1129931)[0m                                             'fsdp_size': -1,
[36m(TaskRunner pid=1129931)[0m                                             'param_offload': False,
[36m(TaskRunner pid=1129931)[0m                                             'reshard_after_forward': True,
[36m(TaskRunner pid=1129931)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1129931)[0m                             'input_tokenizer': '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b',
[36m(TaskRunner pid=1129931)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=1129931)[0m                             'trust_remote_code': False,
[36m(TaskRunner pid=1129931)[0m                             'use_fused_kernels': False,
[36m(TaskRunner pid=1129931)[0m                             'use_remove_padding': False,
[36m(TaskRunner pid=1129931)[0m                             'use_shm': False},
[36m(TaskRunner pid=1129931)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1129931)[0m                                'all_ranks': False,
[36m(TaskRunner pid=1129931)[0m                                'discrete': False,
[36m(TaskRunner pid=1129931)[0m                                'ranks': []},
[36m(TaskRunner pid=1129931)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=1129931)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(TaskRunner pid=1129931)[0m                                      'memory_limit_mb': 1024,
[36m(TaskRunner pid=1129931)[0m                                      'url': None},
[36m(TaskRunner pid=1129931)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=1129931)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1129931)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=1129931)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=1129931)[0m              'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=1129931)[0m                                            'cuda-memory-usage': 'true',
[36m(TaskRunner pid=1129931)[0m                                            'trace': 'cuda,nvtx,cublas,ucx'},
[36m(TaskRunner pid=1129931)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=1129931)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=1129931)[0m              'default_local_dir': '/mnt/task_wrapper/user_output/artifacts/checkpoints/em-new/em-reslen32-60-120-penalty004-nosys',
[36m(TaskRunner pid=1129931)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=1129931)[0m              'device': 'cuda',
[36m(TaskRunner pid=1129931)[0m              'esi_redundant_time': 0,
[36m(TaskRunner pid=1129931)[0m              'experiment_name': 'em-reslen32-60-120-penalty004-nosys',
[36m(TaskRunner pid=1129931)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=1129931)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=1129931)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=1129931)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=1129931)[0m              'n_gpus_per_node': 8,
[36m(TaskRunner pid=1129931)[0m              'nnodes': 1,
[36m(TaskRunner pid=1129931)[0m              'npu_profile': {'options': {'analysis': True,
[36m(TaskRunner pid=1129931)[0m                                          'level': 'level1',
[36m(TaskRunner pid=1129931)[0m                                          'record_shapes': False,
[36m(TaskRunner pid=1129931)[0m                                          'save_path': './profiler_data',
[36m(TaskRunner pid=1129931)[0m                                          'with_cpu': True,
[36m(TaskRunner pid=1129931)[0m                                          'with_memory': False,
[36m(TaskRunner pid=1129931)[0m                                          'with_module': False,
[36m(TaskRunner pid=1129931)[0m                                          'with_npu': True,
[36m(TaskRunner pid=1129931)[0m                                          'with_stack': False}},
[36m(TaskRunner pid=1129931)[0m              'profile_steps': None,
[36m(TaskRunner pid=1129931)[0m              'project_name': 'em-new',
[36m(TaskRunner pid=1129931)[0m              'q_steps': 60,
[36m(TaskRunner pid=1129931)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=1129931)[0m              'ref_update_freq': 120,
[36m(TaskRunner pid=1129931)[0m              'resume_from_path': None,
[36m(TaskRunner pid=1129931)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=1129931)[0m              'rollout_data_dir': None,
[36m(TaskRunner pid=1129931)[0m              'save_freq': 40,
[36m(TaskRunner pid=1129931)[0m              'test_freq': -1,
[36m(TaskRunner pid=1129931)[0m              'total_epochs': 1,
[36m(TaskRunner pid=1129931)[0m              'total_training_steps': None,
[36m(TaskRunner pid=1129931)[0m              'use_legacy_worker_impl': 'auto',
[36m(TaskRunner pid=1129931)[0m              'val_before_train': False,
[36m(TaskRunner pid=1129931)[0m              'val_only': False,
[36m(TaskRunner pid=1129931)[0m              'validation_data_dir': None,
[36m(TaskRunner pid=1129931)[0m              'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(TaskRunner pid=1129931)[0m                                        'capture-range-end': None,
[36m(TaskRunner pid=1129931)[0m                                        'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=1129931)[0m                                        'cuda-memory-usage': 'true',
[36m(TaskRunner pid=1129931)[0m                                        'kill': 'none',
[36m(TaskRunner pid=1129931)[0m                                        'trace': 'cuda,nvtx,cublas,ucx'}}}
[36m(TaskRunner pid=1129931)[0m 2025-08-19 21:32:59.358375: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[36m(TaskRunner pid=1129931)[0m 2025-08-19 21:32:59.374698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(TaskRunner pid=1129931)[0m 2025-08-19 21:32:59.389960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(TaskRunner pid=1129931)[0m 2025-08-19 21:32:59.394202: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(TaskRunner pid=1129931)[0m 2025-08-19 21:32:59.405472: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(TaskRunner pid=1129931)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(TaskRunner pid=1129931)[0m 2025-08-19 21:33:00.289371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[36m(TaskRunner pid=1129931)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=1129931)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1129931)[0m WARNING:2025-08-19 21:33:04,137:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   0%|          | 0/629183 [00:00<?, ? examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   0%|          | 1000/629183 [00:01<12:39, 826.84 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   0%|          | 2000/629183 [00:01<06:08, 1700.49 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   1%|          | 7000/629183 [00:01<01:30, 6891.97 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   2%|▏         | 11000/629183 [00:01<00:54, 11331.06 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   3%|▎         | 16000/629183 [00:01<00:36, 16764.80 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   3%|▎         | 22000/629183 [00:01<00:25, 23789.37 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   4%|▍         | 28000/629183 [00:02<00:19, 30068.35 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   5%|▌         | 33000/629183 [00:02<00:18, 33043.17 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   6%|▋         | 40000/629183 [00:02<00:14, 39453.81 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   7%|▋         | 47000/629183 [00:02<00:13, 44455.95 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):   9%|▊         | 54000/629183 [00:02<00:12, 47345.45 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  10%|█         | 66000/629183 [00:02<00:09, 61315.45 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  12%|█▏        | 77000/629183 [00:02<00:07, 69391.83 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  14%|█▍        | 90000/629183 [00:02<00:06, 80093.40 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  17%|█▋        | 104000/629183 [00:03<00:05, 90537.00 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  19%|█▊        | 117000/629183 [00:03<00:05, 92956.04 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  21%|██        | 131730/629183 [00:03<00:04, 104386.15 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  23%|██▎       | 145460/629183 [00:03<00:04, 105268.41 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  26%|██▌       | 161190/629183 [00:03<00:04, 112727.52 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  28%|██▊       | 175920/629183 [00:03<00:04, 113292.64 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  30%|██▉       | 188650/629183 [00:03<00:04, 109447.79 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  32%|███▏      | 203650/629183 [00:03<00:03, 112698.94 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  35%|███▍      | 219380/629183 [00:04<00:03, 116944.27 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  37%|███▋      | 235110/629183 [00:04<00:03, 120568.53 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  40%|███▉      | 250110/629183 [00:04<00:03, 121075.91 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  42%|████▏     | 266840/629183 [00:04<00:02, 125471.88 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  45%|████▍     | 282570/629183 [00:04<00:02, 127734.03 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  48%|████▊     | 299030/629183 [00:04<00:02, 127504.48 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  50%|████▉     | 312760/629183 [00:04<00:02, 122166.78 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  52%|█████▏    | 326490/629183 [00:04<00:02, 119246.26 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  55%|█████▍    | 343490/629183 [00:04<00:02, 125219.52 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  57%|█████▋    | 361220/629183 [00:05<00:02, 130056.18 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  60%|█████▉    | 374950/629183 [00:05<00:02, 124127.39 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  62%|██████▏   | 391410/629183 [00:05<00:01, 125716.66 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  65%|██████▍   | 408140/629183 [00:05<00:01, 128571.05 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  68%|██████▊   | 429870/629183 [00:05<00:01, 147261.63 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  71%|███████   | 445600/629183 [00:05<00:01, 141146.70 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  73%|███████▎  | 460330/629183 [00:05<00:01, 137294.88 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  76%|███████▌  | 475060/629183 [00:05<00:01, 132921.20 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  78%|███████▊  | 489790/629183 [00:06<00:01, 134700.43 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  80%|████████  | 503790/629183 [00:06<00:00, 127272.84 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  82%|████████▏ | 517519/629183 [00:06<00:00, 123304.09 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  84%|████████▍ | 530977/629183 [00:06<00:00, 122440.32 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  86%|████████▋ | 543977/629183 [00:06<00:00, 118696.35 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  88%|████████▊ | 556706/629183 [00:06<00:00, 111863.51 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  90%|█████████ | 568164/629183 [00:06<00:00, 105714.55 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  92%|█████████▏| 578893/629183 [00:06<00:00, 96008.50 examples/s] 
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  94%|█████████▎| 588893/629183 [00:07<00:00, 87602.74 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  95%|█████████▌| 598351/629183 [00:07<00:00, 81308.13 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  96%|█████████▋| 607080/629183 [00:07<00:00, 71832.48 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  98%|█████████▊| 614809/629183 [00:07<00:00, 66960.19 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40):  99%|█████████▉| 621996/629183 [00:07<00:00, 52668.42 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40): 100%|█████████▉| 628454/629183 [00:08<00:00, 41995.51 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=40): 100%|██████████| 629183/629183 [00:08<00:00, 75888.50 examples/s]
[36m(TaskRunner pid=1129931)[0m dataset len: 626234
[36m(TaskRunner pid=1129931)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=1129931)[0m num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.
[36m(TaskRunner pid=1129931)[0m WARNING:2025-08-19 21:33:12,995:num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.
[36m(TaskRunner pid=1129931)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1129931)[0m WARNING:2025-08-19 21:33:12,996:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):   0%|          | 0/10 [00:00<?, ? examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  10%|█         | 1/10 [00:00<00:06,  1.44 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  20%|██        | 2/10 [00:00<00:02,  2.84 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  40%|████      | 4/10 [00:00<00:01,  5.51 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  50%|█████     | 5/10 [00:01<00:00,  6.21 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  60%|██████    | 6/10 [00:01<00:00,  6.83 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  70%|███████   | 7/10 [00:01<00:00,  7.22 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  80%|████████  | 8/10 [00:01<00:00,  7.59 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10):  90%|█████████ | 9/10 [00:01<00:00,  7.81 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10): 100%|██████████| 10/10 [00:01<00:00,  8.31 examples/s]
[36m(TaskRunner pid=1129931)[0m Filter (num_proc=10): 100%|██████████| 10/10 [00:01<00:00,  5.59 examples/s]
[36m(TaskRunner pid=1129931)[0m dataset len: 10
[36m(TaskRunner pid=1129931)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=1129931)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1129931)[0m Size of train dataloader: 611, Size of val dataloader: 1
[36m(TaskRunner pid=1129931)[0m Total training steps: 611
[36m(TaskRunner pid=1129931)[0m colocated worker base class <class 'verl.single_controller.base.worker.Worker'>
[36m(TaskRunner pid=1129931)[0m WARNING:2025-08-19 21:33:15,630:Waiting for register center actor TV3h50_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(pid=1141645)[0m 2025-08-19 21:33:21.633855: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[36m(pid=1141645)[0m 2025-08-19 21:33:21.648477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(pid=1141645)[0m 2025-08-19 21:33:21.665133: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(pid=1141645)[0m 2025-08-19 21:33:21.670028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(pid=1141645)[0m 2025-08-19 21:33:21.682595: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(pid=1141645)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(pid=1141645)[0m 2025-08-19 21:33:22.607657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[36m(pid=1141971)[0m 2025-08-19 21:33:33.479373: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[36m(pid=1141971)[0m 2025-08-19 21:33:33.493976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(pid=1141971)[0m 2025-08-19 21:33:33.510577: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(pid=1141971)[0m 2025-08-19 21:33:33.515490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(pid=1141971)[0m 2025-08-19 21:33:33.528269: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(pid=1141971)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(pid=1141969)[0m 2025-08-19 21:33:33.903297: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[36m(pid=1141969)[0m 2025-08-19 21:33:33.917922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
[36m(pid=1141969)[0m 2025-08-19 21:33:33.934686: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
[36m(pid=1141969)[0m 2025-08-19 21:33:33.939636: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[36m(pid=1141969)[0m 2025-08-19 21:33:33.952433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[36m(pid=1141969)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[36m(pid=1141971)[0m 2025-08-19 21:33:34.518044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[36m(WorkerDict pid=1141973)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=1141973)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(WorkerDict pid=1141975)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1141975)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=1141973)[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.66it/s]
[36m(WorkerDict pid=1141645)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=1141645)[0m   "architectures": [
[36m(WorkerDict pid=1141645)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=1141645)[0m   ],
[36m(WorkerDict pid=1141645)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=1141645)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=1141645)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=1141645)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=1141645)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=1141645)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=1141645)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=1141645)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=1141645)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=1141645)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=1141645)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=1141645)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=1141645)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=1141645)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=1141645)[0m   "rope_scaling": null,
[36m(WorkerDict pid=1141645)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=1141645)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=1141645)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=1141645)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=1141645)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=1141645)[0m   "use_cache": true,
[36m(WorkerDict pid=1141645)[0m   "use_mrope": false,
[36m(WorkerDict pid=1141645)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=1141645)[0m   "vocab_size": 151936
[36m(WorkerDict pid=1141645)[0m }
[36m(WorkerDict pid=1141645)[0m 
[36m(pid=1141973)[0m 2025-08-19 21:33:35.050831: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=1141973)[0m 2025-08-19 21:33:35.065569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered[32m [repeated 5x across cluster][0m
[36m(pid=1141973)[0m 2025-08-19 21:33:35.082273: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered[32m [repeated 5x across cluster][0m
[36m(pid=1141973)[0m 2025-08-19 21:33:35.087257: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered[32m [repeated 5x across cluster][0m
[36m(pid=1141973)[0m 2025-08-19 21:33:35.100091: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 5x across cluster][0m
[36m(pid=1141973)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 5x across cluster][0m
[36m(pid=1141973)[0m 2025-08-19 21:33:36.100188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1141645)[0m Qwen2ForCausalLM contains 3.09B parameters
[36m(WorkerDict pid=1141645)[0m wrap_policy: functools.partial(<function _or_policy at 0x7d31ee9dae60>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7d31ee9dad40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=1141645)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: NCCL_FASTRAK_LLCM_DEVICE_DIRECTORY=/dev/aperture_devices (expected unset)
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: NCCL_LIB_DIR=/usr/local/nvidia/lib64 (expected unset)
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: NCCL_DYNAMIC_CHUNK_SIZE=524288 (expected unset)
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: NCCL_TESTS_VERSION=2.13.6 (expected unset)
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: cpu affinity settings not subset, curr=0xffff,ffffffff,ffffffff,ffffffff,ffffffff,ffffffff,ffffffff (expected 0xffffffff,00000000)
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:155 NCCL WARN Cannot find communicatorTunerConfig for communicator(num_node:1, num_rank:8) with config:communicator_configs {
[36m(WorkerDict pid=1141645)[0m   node_range {
[36m(WorkerDict pid=1141645)[0m     min: 2
[36m(WorkerDict pid=1141645)[0m     max: 3
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   rank_per_node_range {
[36m(WorkerDict pid=1141645)[0m     min: 1
[36m(WorkerDict pid=1141645)[0m     max: 2
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_ALL_REDUCE
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_TREE
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_DEFAULT
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m         max: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_RING
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 4
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: AL
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:271 NCCL WARN No communicator config selected from config:communicator_configs {
[36m(WorkerDict pid=1141645)[0m   node_range {
[36m(WorkerDict pid=1141645)[0m     min: 2
[36m(WorkerDict pid=1141645)[0m     max: 3
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   rank_per_node_range {
[36m(WorkerDict pid=1141645)[0m     min: 1
[36m(WorkerDict pid=1141645)[0m     max: 2
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_ALL_REDUCE
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_TREE
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_DEFAULT
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m         max: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_RING
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 4
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_RING
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m }
[36m(WorkerDict pid=1141645)[0m communicator_conf
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1143397 [0] /nccl-tuner-config-based/src/tuner_tcpx.cc:70 NCCL WARN No communicator found for nRanks:8, nNodes:1 from config_path:/usr/local/nvidia/lib64/a3plus_tuner_config.textproto
[36m(WorkerDict pid=1141645)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141645)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141974)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141974:1143410 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: NCCL_FASTRAK_LLCM_DEVICE_DIRECTORY=/dev/aperture_devices (expected unset)[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141974)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141974:1143410 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: NCCL_TESTS_VERSION=2.13.6 (expected unset)[32m [repeated 21x across cluster][0m
[36m(WorkerDict pid=1141974)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141974:1143410 [0] /nccl-shim-net/src/guest_config_checker.cc:101 NCCL WARN NCCL/NET (shim) mismatch recommended: cpu affinity settings not subset, curr=0xffff,ffffffff,ffffffff,ffffffff,ffffffff,ffffffff,ffffffff (expected 0xffffffff,00000000)[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m   }
[36m(WorkerDict pid=1141975)[0m   }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m     }
[36m(WorkerDict pid=1141975)[0m   }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m     }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m   }
[36m(WorkerDict pid=1141975)[0m   }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m     }
[36m(WorkerDict pid=1141975)[0m   }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m     }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m       }
[36m(WorkerDict pid=1141975)[0m     }
[36m(WorkerDict pid=1141975)[0m   }
[36m(WorkerDict pid=1141975)[0m }
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141645)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=1141645)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=1141645)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=1141645)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141645)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141645)[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 21.14it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141645)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=1141645)[0m   "architectures": [
[36m(WorkerDict pid=1141645)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=1141645)[0m   ],
[36m(WorkerDict pid=1141645)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=1141645)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=1141645)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=1141645)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=1141645)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=1141645)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=1141645)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=1141645)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=1141645)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=1141645)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=1141645)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=1141645)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=1141645)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=1141645)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=1141645)[0m   "rope_scaling": null,
[36m(WorkerDict pid=1141645)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=1141645)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=1141645)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=1141645)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=1141645)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=1141645)[0m   "use_cache": true,
[36m(WorkerDict pid=1141645)[0m   "use_mrope": false,
[36m(WorkerDict pid=1141645)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=1141645)[0m   "vocab_size": 151936
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.72s/it]
[36m(WorkerDict pid=1141969)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141969:1143408 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:155 NCCL WARN Cannot find communicatorTunerConfig for communicator(num_node:1, num_rank:8) with config:communicator_configs {[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m   node_range {[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         min: 65536[32m [repeated 70x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         max: 65536[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m   rank_per_node_range {[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m   coll_configs {[32m [repeated 28x across cluster][0m
[36m(WorkerDict pid=1141969)[0m     coll_type: COLL_ALL_REDUCE[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m     msg_size_tuning_rules {[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m       per_rank_message_size {[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m       coll_tuning_spec {[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         num_channel: 4[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         protocol: PROTO_SIMPLE[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         algorithm: ALGO_TREE[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m     coll_type: COLL_DEFAULT[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         algorithm: ALGO_RING[32m [repeated 21x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         algorithm: AL[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141969:1143408 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:271 NCCL WARN No communicator config selected from config:communicator_configs {[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m communicator_conf[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141969:1143408 [0] /nccl-tuner-config-based/src/tuner_tcpx.cc:70 NCCL WARN No communicator found for nRanks:8, nNodes:1 from config_path:/usr/local/nvidia/lib64/a3plus_tuner_config.textproto[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141975)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1141975)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=1141645)[0m }[32m [repeated 145x across cluster][0m
[36m(WorkerDict pid=1141975)[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.88s/it]
[36m(WorkerDict pid=1141970)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141970)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 8x across cluster][0m
[36m(WorkerDict pid=1141645)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1141645)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=1141645)[0m Qwen2ForCausalLM contains 3.09B parameters
[36m(WorkerDict pid=1141645)[0m wrap_policy: functools.partial(<function _or_policy at 0x7d31ee9dae60>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7d31ee9dad40>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=1141645)[0m Total steps: 611, num_warmup_steps: 0
[36m(WorkerDict pid=1141645)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=1141645)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=1141645)[0m   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=13.29 GB):   0%|          | 0/23 [00:00<?, ?it/s]
[36m(WorkerDict pid=1141970)[0m Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.73s/it][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141970)[0m Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.92s/it][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141645)[0m Capturing batches (avail_mem=13.29 GB):   4%|▍         | 1/23 [00:00<00:15,  1.41it/s]Capturing batches (avail_mem=13.07 GB):   4%|▍         | 1/23 [00:00<00:15,  1.41it/s]
[36m(WorkerDict pid=1141975)[0m   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=13.40 GB):   0%|          | 0/23 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141974)[0m Capturing batches (avail_mem=12.20 GB):  48%|████▊     | 11/23 [00:06<00:06,  1.75it/s]Capturing batches (avail_mem=12.18 GB):  48%|████▊     | 11/23 [00:06<00:06,  1.75it/s][32m [repeated 70x across cluster][0m
[36m(WorkerDict pid=1141973)[0m Capturing batches (avail_mem=12.34 GB):  39%|███▉      | 9/23 [00:05<00:09,  1.54it/s]
[36m(WorkerDict pid=1141645)[0m Capturing batches (avail_mem=11.91 GB):  91%|█████████▏| 21/23 [00:10<00:00,  2.12it/s]Capturing batches (avail_mem=11.90 GB):  91%|█████████▏| 21/23 [00:10<00:00,  2.12it/s]
[36m(WorkerDict pid=1141645)[0m Capturing batches (avail_mem=11.90 GB):  96%|█████████▌| 22/23 [00:10<00:00,  2.13it/s]Capturing batches (avail_mem=11.89 GB):  96%|█████████▌| 22/23 [00:10<00:00,  2.13it/s]
[36m(WorkerDict pid=1141972)[0m Capturing batches (avail_mem=11.90 GB):  78%|███████▊  | 18/23 [00:10<00:02,  1.91it/s]Capturing batches (avail_mem=11.89 GB):  78%|███████▊  | 18/23 [00:10<00:02,  1.91it/s][32m [repeated 65x across cluster][0m
[36m(WorkerDict pid=1141971)[0m Capturing batches (avail_mem=12.18 GB):  48%|████▊     | 11/23 [00:06<00:07,  1.64it/s][32m [repeated 5x across cluster][0m
[36m(WorkerDict pid=1141645)[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1141645)[0m   warnings.warn(
[36m(WorkerDict pid=1141975)[0m Capturing batches (avail_mem=12.00 GB):  96%|█████████▌| 22/23 [00:14<00:00,  1.65it/s]Capturing batches (avail_mem=11.99 GB):  96%|█████████▌| 22/23 [00:14<00:00,  1.65it/s][32m [repeated 21x across cluster][0m
[36m(WorkerDict pid=1141975)[0m Capturing batches (avail_mem=12.02 GB):  87%|████████▋ | 20/23 [00:12<00:01,  1.62it/s]Capturing batches (avail_mem=12.01 GB):  87%|████████▋ | 20/23 [00:12<00:01,  1.62it/s][32m [repeated 20x across cluster][0m
[36m(WorkerDict pid=1141969)[0m Capturing batches (avail_mem=11.87 GB):  83%|████████▎ | 19/23 [00:12<00:02,  1.64it/s][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=1141975)[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141975)[0m   warnings.warn([32m [repeated 7x across cluster][0m
[36m(TaskRunner pid=1129931)[0m wandb: Currently logged in as: shenaozhang (shenaoz) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(TaskRunner pid=1129931)[0m wandb: Tracking run with wandb version 0.21.1
[36m(TaskRunner pid=1129931)[0m wandb: Run data is saved locally in /mnt/task_runtime/verl/wandb/run-20250819_213500-a3sluq72
[36m(TaskRunner pid=1129931)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(TaskRunner pid=1129931)[0m wandb: Syncing run em-reslen32-60-120-penalty004-nosys
[36m(TaskRunner pid=1129931)[0m wandb: ⭐️ View project at https://wandb.ai/shenaoz/em-new
[36m(TaskRunner pid=1129931)[0m wandb: 🚀 View run at https://wandb.ai/shenaoz/em-new/runs/a3sluq72
[36m(TaskRunner pid=1129931)[0m Training Progress:   0%|          | 0/611 [00:00<?, ?it/s]
[36m(TaskRunner pid=1129931)[0m Checkpoint tracker file does not exist: /mnt/task_wrapper/user_output/artifacts/checkpoints/em-new/em-reslen32-60-120-penalty004-nosys/latest_checkpointed_iteration.txt
[36m(TaskRunner pid=1129931)[0m Training from scratch
[36m(WorkerDict pid=1141969)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1141969)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch[32m [repeated 6x across cluster][0m
[36m(TaskRunner pid=1129931)[0m global_steps 1
[36m(WorkerDict pid=1141645)[0m /mnt/task_runtime/verl/verl/workers/rollout/sglang_rollout/utils.py:49: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
[36m(WorkerDict pid=1141645)[0m   tensor_data = torch.ByteTensor(np.frombuffer(serialized_data, dtype=np.uint8)).to(device)
[36m(WorkerDict pid=1141975)[0m Capturing batches (avail_mem=11.99 GB): 100%|██████████| 23/23 [00:14<00:00,  1.70it/s]Capturing batches (avail_mem=11.99 GB): 100%|██████████| 23/23 [00:14<00:00,  1.57it/s]
[36m(WorkerDict pid=1141975)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1146537 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:155 NCCL WARN Cannot find communicatorTunerConfig for communicator(num_node:1, num_rank:1) with config:communicator_configs {
[36m(WorkerDict pid=1141645)[0m   node_range {
[36m(WorkerDict pid=1141645)[0m     min: 2
[36m(WorkerDict pid=1141645)[0m     max: 3
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   rank_per_node_range {
[36m(WorkerDict pid=1141645)[0m     min: 1
[36m(WorkerDict pid=1141645)[0m     max: 2
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_ALL_REDUCE
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_TREE
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_DEFAULT
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m         max: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_RING
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 4
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: AL
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1146537 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:271 NCCL WARN No communicator config selected from config:communicator_configs {
[36m(WorkerDict pid=1141645)[0m   node_range {
[36m(WorkerDict pid=1141645)[0m     min: 2
[36m(WorkerDict pid=1141645)[0m     max: 3
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   rank_per_node_range {
[36m(WorkerDict pid=1141645)[0m     min: 1
[36m(WorkerDict pid=1141645)[0m     max: 2
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_ALL_REDUCE
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_TREE
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m   coll_configs {
[36m(WorkerDict pid=1141645)[0m     coll_type: COLL_DEFAULT
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 0
[36m(WorkerDict pid=1141645)[0m         max: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 2
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_RING
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m     msg_size_tuning_rules {
[36m(WorkerDict pid=1141645)[0m       per_rank_message_size {
[36m(WorkerDict pid=1141645)[0m         min: 65536
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m       coll_tuning_spec {
[36m(WorkerDict pid=1141645)[0m         num_channel: 4
[36m(WorkerDict pid=1141645)[0m         protocol: PROTO_SIMPLE
[36m(WorkerDict pid=1141645)[0m         algorithm: ALGO_RING
[36m(WorkerDict pid=1141645)[0m       }
[36m(WorkerDict pid=1141645)[0m     }
[36m(WorkerDict pid=1141645)[0m   }
[36m(WorkerDict pid=1141645)[0m }
[36m(WorkerDict pid=1141645)[0m communicator_conf
[36m(WorkerDict pid=1141645)[0m 
[36m(WorkerDict pid=1141645)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141645:1146537 [0] /nccl-tuner-config-based/src/tuner_tcpx.cc:70 NCCL WARN No communicator found for nRanks:1, nNodes:1 from config_path:/usr/local/nvidia/lib64/a3plus_tuner_config.textproto
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141975)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141973)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141972)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141971)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141974)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141970)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(WorkerDict pid=1141969)[0m 
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a python function to find the number of ways to climb a staircase of n steps, given that one can take either 1 or 2 steps at a time.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def staircase(n): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res:  
[36m(TaskRunner pid=1129931)[0m     # Base case: one way to get to the first step
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     if n <= 1: end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:         return n end3prompt
[36m(TaskRunner pid=1129931)[0m third_res:  + 1
[36m(TaskRunner pid=1129931)[0m     
[36m(TaskRunner pid=1129931)[0m     count = [0] * (n + 1) 
[36m(TaskRunner pid=1129931)[0m     count[0] = 1
[36m(TaskRunner pid=1129931)[0m     count[1] endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:     a, b = 1, 2 end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m         # Note that i runs from n to 2 because
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(WorkerDict pid=1141969)[0m NCCL version 2.21.5+cuda12.4[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=1141969)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141969:1146535 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:155 NCCL WARN Cannot find communicatorTunerConfig for communicator(num_node:1, num_rank:1) with config:communicator_configs {[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m   node_range {[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         min: 65536[32m [repeated 70x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         max: 65536[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m }[32m [repeated 168x across cluster][0m
[36m(WorkerDict pid=1141969)[0m   rank_per_node_range {[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m   coll_configs {[32m [repeated 28x across cluster][0m
[36m(WorkerDict pid=1141969)[0m     coll_type: COLL_ALL_REDUCE[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m     msg_size_tuning_rules {[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m       per_rank_message_size {[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m       coll_tuning_spec {[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         num_channel: 4[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         protocol: PROTO_SIMPLE[32m [repeated 42x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         algorithm: ALGO_TREE[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m     coll_type: COLL_DEFAULT[32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         algorithm: ALGO_RING[32m [repeated 21x across cluster][0m
[36m(WorkerDict pid=1141969)[0m         algorithm: AL[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141969:1146535 [0] /nccl-tuner-config-based/src/config_based_tuner.cc:271 NCCL WARN No communicator config selected from config:communicator_configs {[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m communicator_conf[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141969)[0m bolt-mcd2umnbr9-t3t3k8znvj:1141969:1146535 [0] /nccl-tuner-config-based/src/tuner_tcpx.cc:70 NCCL WARN No communicator found for nRanks:1, nNodes:1 from config_path:/usr/local/nvidia/lib64/a3plus_tuner_config.textproto[32m [repeated 7x across cluster][0m
[36m(TaskRunner pid=1129931)[0m Training Progress:   0%|          | 1/611 [01:23<14:13:40, 83.97s/it]
[36m(WorkerDict pid=1141970)[0m /mnt/task_runtime/verl/verl/workers/rollout/sglang_rollout/utils.py:49: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=1141970)[0m   tensor_data = torch.ByteTensor(np.frombuffer(serialized_data, dtype=np.uint8)).to(device)[32m [repeated 7x across cluster][0m
[36m(TaskRunner pid=1129931)[0m step:1 - global_seqlen/min:158195 - global_seqlen/max:195670 - global_seqlen/minmax_diff:37475 - global_seqlen/balanced_min:170838 - global_seqlen/balanced_max:170839 - global_seqlen/mean:170838.75 - actor/entropy:1.4018564224243164 - actor/pg_loss:0.38831942435353994 - actor/pg_clipfrac:0.006842337665148079 - actor/ppo_kl:-0.0033261558346566744 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:1.3692618161439896 - perf/mfu/actor:0.24931956130457755 - perf/max_memory_allocated_gb:23.471529960632324 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:78.54156112670898 - actor/lr:2e-06 - training/global_step:1 - training/epoch:0 - critic/rewards/mean:0.3990979492664337 - critic/rewards/max:0.9704465270042419 - critic/rewards/min:0.0 - critic/advantages/mean:-0.38292378187179565 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888503074645996 - critic/format_reward/mean:0.575560450553894 - response_length/mean:14.0388822555542 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:40.31640625 - prompt_length/max:128.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0009765625 - timing_s/start_profile:2.0289997337386012e-05 - timing_s/generate_sequences:51.9848518371582 - timing_s/reshard:1.5371193885803223 - timing_s/gen:54.514430723007536 - timing_s/reward:0.8602888909808826 - timing_s/old_log_prob:6.147290759021416 - timing_s/ref:5.667213845998049 - timing_s/adv:0.9676170879974961 - timing_s/update_actor:14.528229988995008 - timing_s/step:82.86233952399925 - timing_s/stop_profile:2.648012014105916e-06 - timing_per_token_ms/update_actor:0.05220365833360594 - timing_per_token_ms/adv:0.003476896490339375 - timing_per_token_ms/ref:0.020363753571086496 - timing_per_token_ms/gen:0.7584186128292465 - perf/total_num_tokens:1366710 - perf/time_per_step:82.86233952399925 - perf/throughput:2061.7176751390216
[36m(TaskRunner pid=1129931)[0m global_steps 2
[36m(TaskRunner pid=1129931)[0m Training Progress:   0%|          | 2/611 [02:45<13:55:39, 82.33s/it]
[36m(TaskRunner pid=1129931)[0m error!! index 1 is out of bounds for dimension 0 with size 1
[36m(TaskRunner pid=1129931)[0m step:2 - global_seqlen/min:147967 - global_seqlen/max:174129 - global_seqlen/minmax_diff:26162 - global_seqlen/balanced_min:158366 - global_seqlen/balanced_max:158367 - global_seqlen/mean:158366.75 - actor/entropy:1.3469611406326294 - actor/pg_loss:0.4618814866989851 - actor/pg_clipfrac:0.01597210846375674 - actor/ppo_kl:-0.003093423969403375 - actor/pg_clipfrac_lower:4.8453449380758684e-05 - actor/grad_norm:1.2023761868476868 - perf/mfu/actor:0.19489566026708927 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:79.05041122436523 - actor/lr:2e-06 - training/global_step:2 - training/epoch:0 - critic/rewards/mean:0.46000242233276367 - critic/rewards/max:0.9686131477355957 - critic/rewards/min:0.0 - critic/advantages/mean:-0.43139341473579407 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888503074645996 - critic/format_reward/mean:0.6428917050361633 - response_length/mean:12.090518951416016 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.9404296875 - prompt_length/max:128.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0009765625 - timing_s/start_profile:4.536996129900217e-06 - timing_s/generate_sequences:52.66245651245117 - timing_s/reshard:1.0759665966033936 - timing_s/gen:54.70837038499303 - timing_s/reward:0.8310174130019732 - timing_s/old_log_prob:3.8452403330011293 - timing_s/ref:3.821437585982494 - timing_s/adv:0.4765650469926186 - timing_s/update_actor:17.12944317201618 - timing_s/step:80.97348915497423 - timing_s/stop_profile:2.4469918571412563e-06 - timing_per_token_ms/update_actor:0.06191996353594895 - timing_per_token_ms/adv:0.001722699917093538 - timing_per_token_ms/ref:0.013813833503093937 - timing_per_token_ms/gen:0.8837692272561651 - perf/total_num_tokens:1266934 - perf/time_per_step:80.97348915497423 - perf/throughput:1955.785179231979
[36m(TaskRunner pid=1129931)[0m global_steps 3
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a function that takes a list of integers and returns a list of intervals where each interval represents the range of consecutive integers in the input list. An interval is represented as a list with two elements, the start and the end of the range. If the input list is empty, return an empty list.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m from typing import List end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt: 
[36m(TaskRunner pid=1129931)[0m def find_consecutive_ranges(nums: List[int]) -> List[List[int]]: end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     if not nums: end3prompt
[36m(TaskRunner pid=1129931)[0m third_res:  return []
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m     nums.sort()
[36m(TaskRunner pid=1129931)[0m     start = nums[0]
[36m(TaskRunner pid=1129931)[0m     end = start
[36m(TaskRunner pid=1129931)[0m     result = []
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m     for i in range(1, len(nums endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:         return [] end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: ```
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m Write a function that takes a list of integers and an integer `k`. Each element of the list is guaranteed to be in the range `[1, endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   0%|          | 3/611 [03:58<13:12:13, 78.18s/it]
[36m(TaskRunner pid=1129931)[0m step:3 - global_seqlen/min:130804 - global_seqlen/max:148350 - global_seqlen/minmax_diff:17546 - global_seqlen/balanced_min:138982 - global_seqlen/balanced_max:138983 - global_seqlen/mean:138982.625 - actor/entropy:1.260055661201477 - actor/pg_loss:0.5126635283231735 - actor/pg_clipfrac:0.024938050017226487 - actor/ppo_kl:-0.006762022476323182 - actor/pg_clipfrac_lower:6.826629396528006e-05 - actor/grad_norm:2.0423054695129395 - perf/mfu/actor:0.2381145898424457 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:79.52006912231445 - actor/lr:2e-06 - training/global_step:3 - training/epoch:0 - critic/rewards/mean:0.5583599209785461 - critic/rewards/max:0.9638972878456116 - critic/rewards/min:0.0 - critic/advantages/mean:-0.5228943228721619 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.7439373135566711 - response_length/mean:9.104615211486816 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:42.9365234375 - prompt_length/max:122.0 - prompt_length/min:18.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.457026418298483e-06 - timing_s/generate_sequences:50.739383697509766 - timing_s/reshard:0.8834415674209595 - timing_s/gen:52.32168563999585 - timing_s/reward:0.8053592570067849 - timing_s/old_log_prob:3.514005300006829 - timing_s/ref:3.439817481994396 - timing_s/adv:0.4420110030041542 - timing_s/update_actor:12.344047110003885 - timing_s/step:73.01193129899912 - timing_s/stop_profile:2.5719928089529276e-06 - timing_per_token_ms/update_actor:0.046327708666610457 - timing_per_token_ms/adv:0.0016588851931727835 - timing_per_token_ms/ref:0.012909774302708392 - timing_per_token_ms/gen:1.1224065161755397 - perf/total_num_tokens:1111861 - perf/time_per_step:73.01193129899912 - perf/throughput:1903.560452754456
[36m(TaskRunner pid=1129931)[0m global_steps 4
[36m(TaskRunner pid=1129931)[0m Training Progress:   1%|          | 4/611 [05:16<13:12:16, 78.31s/it]
[36m(TaskRunner pid=1129931)[0m error!! index 1 is out of bounds for dimension 0 with size 1
[36m(TaskRunner pid=1129931)[0m step:4 - global_seqlen/min:111770 - global_seqlen/max:128849 - global_seqlen/minmax_diff:17079 - global_seqlen/balanced_min:119337 - global_seqlen/balanced_max:119338 - global_seqlen/mean:119337.25 - actor/entropy:1.1673287153244019 - actor/pg_loss:0.4657884733751416 - actor/pg_clipfrac:0.032595811411738396 - actor/ppo_kl:-0.010473456772160716 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:3.1372129023075104 - perf/mfu/actor:0.17423905514049154 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:79.99105834960938 - actor/lr:2e-06 - training/global_step:4 - training/epoch:0 - critic/rewards/mean:0.6799508929252625 - critic/rewards/max:0.9667368531227112 - critic/rewards/min:0.0 - critic/advantages/mean:-0.5003891587257385 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.8647686839103699 - response_length/mean:5.820101261138916 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.171875 - prompt_length/max:122.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:4.7600187826901674e-06 - timing_s/generate_sequences:53.8186149597168 - timing_s/reshard:0.9729835987091064 - timing_s/gen:56.425597155990545 - timing_s/reward:0.7452392079867423 - timing_s/old_log_prob:3.095082547981292 - timing_s/ref:3.0871653410140425 - timing_s/adv:0.464244499016786 - timing_s/update_actor:14.429103661997942 - timing_s/step:78.33748136501526 - timing_s/stop_profile:2.375018084421754e-06 - timing_per_token_ms/update_actor:0.05997160662157282 - timing_per_token_ms/adv:0.0019295369361431792 - timing_per_token_ms/ref:0.012831168847629715 - timing_per_token_ms/gen:1.8935451688267282 - perf/total_num_tokens:954698 - perf/time_per_step:78.33748136501526 - perf/throughput:1523.3735872097468
[36m(TaskRunner pid=1129931)[0m global_steps 5
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Create a python function to find the longest common prefix among a given list of strings.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def find_longest_prefix(strs): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     if not strs: return "" end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     shortest_str = min(strs, key=len) end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:     for i, char in enumerate(shortest_str): end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   1%|          | 5/611 [06:26<12:40:11, 75.27s/it]
[36m(TaskRunner pid=1129931)[0m step:5 - global_seqlen/min:94773 - global_seqlen/max:112354 - global_seqlen/minmax_diff:17581 - global_seqlen/balanced_min:103774 - global_seqlen/balanced_max:103775 - global_seqlen/mean:103774.375 - actor/entropy:1.079930305480957 - actor/pg_loss:0.39033730467781425 - actor/pg_clipfrac:0.02938629232812673 - actor/ppo_kl:-0.008501042204443365 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:3.2559115290641785 - perf/mfu/actor:0.20894677683974616 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:80.48857116699219 - actor/lr:2e-06 - training/global_step:5 - training/epoch:0 - critic/rewards/mean:0.7416412830352783 - critic/rewards/max:0.9660813808441162 - critic/rewards/min:0.0 - critic/advantages/mean:-0.44253775477409363 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.9192759394645691 - response_length/mean:4.23378849029541 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:40.6796875 - prompt_length/max:119.0 - prompt_length/min:17.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:4.953006282448769e-06 - timing_s/generate_sequences:50.682273864746094 - timing_s/reshard:0.7747282981872559 - timing_s/gen:52.048701774998335 - timing_s/reward:0.752346706984099 - timing_s/old_log_prob:2.870804728998337 - timing_s/ref:2.8782019619829953 - timing_s/adv:0.4375857539998833 - timing_s/update_actor:10.482057184999576 - timing_s/step:69.60481641502702 - timing_s/stop_profile:3.295019268989563e-06 - timing_per_token_ms/update_actor:0.04558268442820587 - timing_per_token_ms/adv:0.001902902548881297 - timing_per_token_ms/ref:0.01251626178317965 - timing_per_token_ms/gen:2.401103065659786 - perf/total_num_tokens:830195 - perf/time_per_step:69.60481641502702 - perf/throughput:1490.9079621909052
[36m(TaskRunner pid=1129931)[0m global_steps 6
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a function that finds the number of continuous subarrays in a given list that sum up to a specific target sum.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m from collections import defaultdict end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt: 
[36m(TaskRunner pid=1129931)[0m def subarray_count(nums, target): end2prompt
[36m(TaskRunner pid=1129931)[0m second_res:  
[36m(TaskRunner pid=1129931)[0m     # Initializes a bucket of length k to store prefix sums 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     memo = defaultdict(int) end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:     memo[0] += 1 end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res:  
[36m(TaskRunner pid=1129931)[0m     # Initialized as 0, count as a built-in running count 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   1%|          | 6/611 [07:38<12:25:17, 73.91s/it]
[36m(TaskRunner pid=1129931)[0m step:6 - global_seqlen/min:93177 - global_seqlen/max:103270 - global_seqlen/minmax_diff:10093 - global_seqlen/balanced_min:98554 - global_seqlen/balanced_max:98554 - global_seqlen/mean:98554.0 - actor/entropy:0.9701818823814392 - actor/pg_loss:0.29480871371924877 - actor/pg_clipfrac:0.038050379778724164 - actor/ppo_kl:-0.013230963915702887 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:5.4198620319366455 - perf/mfu/actor:0.15974643227498228 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:80.80270385742188 - actor/lr:2e-06 - training/global_step:6 - training/epoch:0 - critic/rewards/mean:0.7730370163917542 - critic/rewards/max:0.9706408381462097 - critic/rewards/min:0.0 - critic/advantages/mean:-0.3186432123184204 - critic/advantages/max:1.78885018825531 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.9498238563537598 - response_length/mean:3.279484510421753 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.9228515625 - prompt_length/max:126.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.265006959438324e-06 - timing_s/generate_sequences:49.95674514770508 - timing_s/reshard:0.6968947052955627 - timing_s/gen:51.45103467698209 - timing_s/reward:0.7559642660198733 - timing_s/old_log_prob:2.7619147060031537 - timing_s/ref:2.6964410970103927 - timing_s/adv:0.4193349230044987 - timing_s/update_actor:12.937876284006052 - timing_s/step:71.1260512440058 - timing_s/stop_profile:3.431981895118952e-06 - timing_per_token_ms/update_actor:0.05590261872700054 - timing_per_token_ms/adv:0.0018118831719403424 - timing_per_token_ms/ref:0.01165091667728584 - timing_per_token_ms/gen:3.0642102538678535 - perf/total_num_tokens:788432 - perf/time_per_step:71.1260512440058 - perf/throughput:1385.6245113608177
[36m(TaskRunner pid=1129931)[0m global_steps 7
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a python function to find the shortest path sum in a triangle. The function should take a list of lists as input, representing the triangle, and return the minimum path sum from top to bottom.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def triangle_min_path_sum(triangle): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     for row in range(len(triangle) - 2, -1, -1): end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:         for col in range(len(triangle[row])): end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:             triangle[row][col] += min(triangle[row + 1][col], triangle[row + 1][col + 1]) end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   1%|          | 7/611 [08:48<12:11:17, 72.65s/it]
[36m(TaskRunner pid=1129931)[0m step:7 - global_seqlen/min:89736 - global_seqlen/max:97985 - global_seqlen/minmax_diff:8249 - global_seqlen/balanced_min:94838 - global_seqlen/balanced_max:94838 - global_seqlen/mean:94838.0 - actor/entropy:0.8736435770988464 - actor/pg_loss:0.28697488296893425 - actor/pg_clipfrac:0.04298403026768938 - actor/ppo_kl:-0.007405254136074291 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:4.626476347446442 - perf/mfu/actor:0.19286548609355833 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.22418975830078 - actor/lr:2e-06 - training/global_step:7 - training/epoch:0 - critic/rewards/mean:0.7771865725517273 - critic/rewards/max:0.9593676328659058 - critic/rewards/min:0.0 - critic/advantages/mean:-0.2772041857242584 - critic/advantages/max:1.78885018825531 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.951856255531311 - response_length/mean:2.6427407264709473 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.0810546875 - prompt_length/max:113.0 - prompt_length/min:17.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.403009708970785e-06 - timing_s/generate_sequences:51.54490661621094 - timing_s/reshard:0.7237303256988525 - timing_s/gen:52.99896593901212 - timing_s/reward:0.7073692370031495 - timing_s/old_log_prob:2.614627407019725 - timing_s/ref:2.596771175012691 - timing_s/adv:0.43664436900871806 - timing_s/update_actor:10.332725751999533 - timing_s/step:69.83562042599078 - timing_s/stop_profile:2.51797609962523e-06 - timing_per_token_ms/update_actor:0.04615588568494526 - timing_per_token_ms/adv:0.0019504734824730456 - timing_per_token_ms/ref:0.01159967625005946 - timing_per_token_ms/gen:3.9169036919983102 - perf/total_num_tokens:758704 - perf/time_per_step:69.83562042599078 - perf/throughput:1358.0175764387434
[36m(TaskRunner pid=1129931)[0m global_steps 8
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a function that finds the minimum number of swaps required to sort a given array in ascending order. A swap operation involves interchanging the positions of two elements in the array.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def minimum_swaps_to_sort(arr): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     n = len(arr) end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     swap_count = 0 end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:     temp_arr = arr.copy() end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   1%|▏         | 8/611 [09:58<12:02:42, 71.91s/it]
[36m(TaskRunner pid=1129931)[0m step:8 - global_seqlen/min:78591 - global_seqlen/max:96778 - global_seqlen/minmax_diff:18187 - global_seqlen/balanced_min:90084 - global_seqlen/balanced_max:90085 - global_seqlen/mean:90084.5 - actor/entropy:0.758051872253418 - actor/pg_loss:0.10260054207174107 - actor/pg_clipfrac:0.028753345366567373 - actor/ppo_kl:-0.0013111972948536277 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:2.2194942235946655 - perf/mfu/actor:0.1879040761742325 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.37873840332031 - actor/lr:2e-06 - training/global_step:8 - training/epoch:0 - critic/rewards/mean:0.7734469175338745 - critic/rewards/max:0.9717636108398438 - critic/rewards/min:0.0 - critic/advantages/mean:-0.1691654771566391 - critic/advantages/max:1.7888503074645996 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.9467334747314453 - response_length/mean:2.254544496536255 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.998046875 - prompt_length/max:128.0 - prompt_length/min:18.0 - prompt_length/clip_ratio:0.0009765625 - timing_s/start_profile:5.873996997252107e-06 - timing_s/generate_sequences:51.94483184814453 - timing_s/reshard:0.6680474877357483 - timing_s/gen:53.25739869099925 - timing_s/reward:0.7237520630005747 - timing_s/old_log_prob:2.5414897200244013 - timing_s/ref:2.583590902009746 - timing_s/adv:0.8310785669891629 - timing_s/update_actor:10.097182135999901 - timing_s/step:70.12717628499377 - timing_s/stop_profile:2.649001544341445e-06 - timing_per_token_ms/update_actor:0.044564754897743086 - timing_per_token_ms/adv:0.0036680345208977387 - timing_per_token_ms/ref:0.011402893773065682 - timing_per_token_ms/gen:4.613719497581808 - perf/total_num_tokens:720676 - perf/time_per_step:70.12717628499377 - perf/throughput:1284.587584617703
[36m(TaskRunner pid=1129931)[0m global_steps 9
[36m(TaskRunner pid=1129931)[0m Training Progress:   1%|▏         | 9/611 [11:14<12:14:09, 73.17s/it]
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a function to find the shortest transformation sequence from beginWord to endWord, such that only one letter can be changed at a time and each transformed word must exist in the word list. Return the length of the shortest transformation sequence, or return 0 if no such sequence exists.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m from collections import deque end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt: 
[36m(TaskRunner pid=1129931)[0m def word_ladder_length(beginWord, endWord, wordList): end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     if endWord not in wordList: end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:         return 0 end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m step:9 - global_seqlen/min:83197 - global_seqlen/max:91074 - global_seqlen/minmax_diff:7877 - global_seqlen/balanced_min:88274 - global_seqlen/balanced_max:88275 - global_seqlen/mean:88274.375 - actor/entropy:0.7095188498497009 - actor/pg_loss:0.09158546591061167 - actor/pg_clipfrac:0.03530693531502038 - actor/ppo_kl:0.02402847672055941 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:5.680753618478775 - perf/mfu/actor:0.14959551304604332 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.56721878051758 - actor/lr:2e-06 - training/global_step:9 - training/epoch:0 - critic/rewards/mean:0.7499879598617554 - critic/rewards/max:0.9700570106506348 - critic/rewards/min:0.0 - critic/advantages/mean:-0.10567162930965424 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.9281795620918274 - response_length/mean:1.9655869007110596 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.0771484375 - prompt_length/max:122.0 - prompt_length/min:17.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.427988409996033e-06 - timing_s/generate_sequences:54.577003479003906 - timing_s/reshard:2.1293983459472656 - timing_s/gen:57.31397143600043 - timing_s/reward:0.7087807950156275 - timing_s/old_log_prob:2.445200196991209 - timing_s/ref:2.415870741009712 - timing_s/adv:0.37464355799602345 - timing_s/update_actor:12.368530126987025 - timing_s/step:75.77380295199691 - timing_s/stop_profile:3.302993718534708e-06 - timing_per_token_ms/update_actor:0.056123955044251016 - timing_per_token_ms/adv:0.0016999981396907606 - timing_per_token_ms/ref:0.010962355224838651 - timing_per_token_ms/gen:5.695059991296202 - perf/total_num_tokens:706195 - perf/time_per_step:75.77380295199691 - perf/throughput:1164.9722141558905
[36m(TaskRunner pid=1129931)[0m global_steps 10
[36m(TaskRunner pid=1129931)[0m Training Progress:   2%|▏         | 10/611 [12:25<12:07:21, 72.62s/it]
[36m(TaskRunner pid=1129931)[0m error!! index 2 is out of bounds for dimension 0 with size 2
[36m(TaskRunner pid=1129931)[0m step:10 - global_seqlen/min:81550 - global_seqlen/max:98012 - global_seqlen/minmax_diff:16462 - global_seqlen/balanced_min:88465 - global_seqlen/balanced_max:88466 - global_seqlen/mean:88465.375 - actor/entropy:0.6990998387336731 - actor/pg_loss:0.13892803818453103 - actor/pg_clipfrac:0.029502269229851663 - actor/ppo_kl:0.0193704814882949 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:2.1875426173210144 - perf/mfu/actor:0.18796058652934955 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.51213836669922 - actor/lr:2e-06 - training/global_step:10 - training/epoch:0 - critic/rewards/mean:0.7283951640129089 - critic/rewards/max:0.9693105816841125 - critic/rewards/min:0.0 - critic/advantages/mean:-0.09834949672222137 - critic/advantages/max:1.7888503074645996 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.9063310623168945 - response_length/mean:1.9975416660308838 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.275390625 - prompt_length/max:128.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0009765625 - timing_s/start_profile:4.649016773328185e-06 - timing_s/generate_sequences:53.57764434814453 - timing_s/reshard:0.6308982968330383 - timing_s/gen:55.07556469499832 - timing_s/reward:0.7166441740118898 - timing_s/old_log_prob:2.392809500976 - timing_s/ref:2.494086565973703 - timing_s/adv:0.44327368901576847 - timing_s/update_actor:9.920343617006438 - timing_s/step:71.13436199599528 - timing_s/stop_profile:2.5149784050881863e-06 - timing_per_token_ms/update_actor:0.04477549849870536 - timing_per_token_ms/adv:0.002000717027887629 - timing_per_token_ms/ref:0.01125706665028761 - timing_per_token_ms/gen:5.385092420949163 - perf/total_num_tokens:707723 - perf/time_per_step:71.13436199599528 - perf/throughput:1243.6377092266664
[36m(TaskRunner pid=1129931)[0m global_steps 11
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a function to find the maximum number of non-overlapping subarrays with sum equals to target.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def max_target_subarray(nums, target): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     count = 0 end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     start = 0 end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:     current_sum = 0 end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   2%|▏         | 11/611 [13:32<11:47:06, 70.71s/it]
[36m(TaskRunner pid=1129931)[0m step:11 - global_seqlen/min:78527 - global_seqlen/max:97875 - global_seqlen/minmax_diff:19348 - global_seqlen/balanced_min:87624 - global_seqlen/balanced_max:87765 - global_seqlen/mean:87712.25 - actor/entropy:0.6928297281265259 - actor/pg_loss:0.020884931946056895 - actor/pg_clipfrac:0.032211472280323505 - actor/ppo_kl:0.016738204983994365 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:5.415944278240204 - perf/mfu/actor:0.19821692761235718 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.63544845581055 - actor/lr:2e-06 - training/global_step:11 - training/epoch:0 - critic/rewards/mean:0.704098105430603 - critic/rewards/max:0.9750877618789673 - critic/rewards/min:0.0 - critic/advantages/mean:-0.010011331178247929 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.880437970161438 - response_length/mean:1.8607639074325562 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.6005859375 - prompt_length/max:121.0 - prompt_length/min:16.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.183013854548335e-06 - timing_s/generate_sequences:49.70915603637695 - timing_s/reshard:0.6770502924919128 - timing_s/gen:50.9508067239949 - timing_s/reward:0.7181434220110532 - timing_s/old_log_prob:2.357509947993094 - timing_s/ref:2.306641772011062 - timing_s/adv:0.4066484929935541 - timing_s/update_actor:9.308076624001842 - timing_s/step:66.18157541198889 - timing_s/stop_profile:2.8850045055150986e-06 - timing_per_token_ms/update_actor:0.041829895323419825 - timing_per_token_ms/adv:0.0018274520701177484 - timing_per_token_ms/ref:0.0103658991829794 - timing_per_token_ms/gen:5.347980617543845 - perf/total_num_tokens:701698 - perf/time_per_step:66.18157541198889 - perf/throughput:1325.3273203906053
[36m(TaskRunner pid=1129931)[0m global_steps 12
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a python function that returns the sum of all the unique multiples of certain numbers up to but not including a given number.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def sum_of_multiples(end, multiples): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     sum = 0 end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     for i in range(1, end): end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:         for j in multiples: end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   2%|▏         | 12/611 [14:47<12:00:21, 72.16s/it]
[36m(TaskRunner pid=1129931)[0m step:12 - global_seqlen/min:85191 - global_seqlen/max:96742 - global_seqlen/minmax_diff:11551 - global_seqlen/balanced_min:89070 - global_seqlen/balanced_max:89071 - global_seqlen/mean:89070.375 - actor/entropy:0.6939104795455933 - actor/pg_loss:-0.01957959806895815 - actor/pg_clipfrac:0.05316796828992665 - actor/ppo_kl:0.042022769164759666 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:6.129765450954437 - perf/mfu/actor:0.1745774653297527 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.59048843383789 - actor/lr:2e-06 - training/global_step:12 - training/epoch:0 - critic/rewards/mean:0.6677030324935913 - critic/rewards/max:0.9575623869895935 - critic/rewards/min:0.0 - critic/advantages/mean:0.011012586764991283 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.8425748944282532 - response_length/mean:1.9522793292999268 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.5048828125 - prompt_length/max:126.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:9.256997145712376e-06 - timing_s/generate_sequences:57.16204071044922 - timing_s/reshard:0.7415810823440552 - timing_s/gen:58.626098187000025 - timing_s/reward:0.6999245310144033 - timing_s/old_log_prob:2.3952426119940355 - timing_s/ref:2.3388888240151573 - timing_s/adv:0.4175622909970116 - timing_s/update_actor:10.689256412006216 - timing_s/step:75.26709865400335 - timing_s/stop_profile:3.908993676304817e-06 - timing_per_token_ms/update_actor:0.048041457204418554 - timing_per_token_ms/adv:0.0018766788034554104 - timing_per_token_ms/ref:0.010511828233310011 - timing_per_token_ms/gen:5.865149474243831 - perf/total_num_tokens:712563 - perf/time_per_step:75.26709865400335 - perf/throughput:1183.390572944085
[36m(TaskRunner pid=1129931)[0m global_steps 13
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a python function to calculate the frequency of each word in a given list of sentences and return the result as a dictionary.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m from collections import defaultdict end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt: 
[36m(TaskRunner pid=1129931)[0m def word_Frequency(sentences, words): end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     frequency = defaultdict(int) end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:     for sentence in sentences: end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   2%|▏         | 13/611 [16:02<12:06:12, 72.86s/it]
[36m(TaskRunner pid=1129931)[0m step:13 - global_seqlen/min:81660 - global_seqlen/max:91131 - global_seqlen/minmax_diff:9471 - global_seqlen/balanced_min:87021 - global_seqlen/balanced_max:87137 - global_seqlen/mean:87093.25 - actor/entropy:0.710082471370697 - actor/pg_loss:-0.06787874503061175 - actor/pg_clipfrac:0.05262747383676469 - actor/ppo_kl:0.02132792171323672 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:4.467269003391266 - perf/mfu/actor:0.16352751396044787 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.70682525634766 - actor/lr:2e-06 - training/global_step:13 - training/epoch:0 - critic/rewards/mean:0.6263724565505981 - critic/rewards/max:0.967378556728363 - critic/rewards/min:0.0 - critic/advantages/mean:0.059606727212667465 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.8040964007377625 - response_length/mean:2.0809414386749268 - response_length/max:21.619047164916992 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.142578125 - prompt_length/max:126.0 - prompt_length/min:17.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:6.652990123257041e-06 - timing_s/generate_sequences:55.66568374633789 - timing_s/reshard:0.6628943681716919 - timing_s/gen:56.88632417397457 - timing_s/reward:0.7215007039776538 - timing_s/old_log_prob:2.463302548014326 - timing_s/ref:2.4813609900011215 - timing_s/adv:0.45192388698342256 - timing_s/update_actor:11.172644265985582 - timing_s/step:74.29738210898358 - timing_s/stop_profile:3.569002728909254e-06 - timing_per_token_ms/update_actor:0.05048540950935257 - timing_per_token_ms/adv:0.0020420915548951123 - timing_per_token_ms/ref:0.011212433040772945 - timing_per_token_ms/gen:5.33922302585231 - perf/total_num_tokens:696746 - perf/time_per_step:74.29738210898358 - perf/throughput:1172.22501692249
[36m(TaskRunner pid=1129931)[0m global_steps 14
[36m(TaskRunner pid=1129931)[0m Training Progress:   2%|▏         | 14/611 [17:18<12:15:01, 73.87s/it]
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a python function to find the longest palindrome in a given string. A palindrome is a string that reads the same backward as forward, e.g., 'radar' or 'madam'.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def findLongestPalindrome(s): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     if len(s) == 0: end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:         return 0 end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:     maxLen = 1 end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m step:14 - global_seqlen/min:87914 - global_seqlen/max:96495 - global_seqlen/minmax_diff:8581 - global_seqlen/balanced_min:91504 - global_seqlen/balanced_max:91505 - global_seqlen/mean:91504.875 - actor/entropy:0.7262138724327087 - actor/pg_loss:-0.15332963899709284 - actor/pg_clipfrac:0.07280205516144633 - actor/ppo_kl:0.03689204357579001 - actor/pg_clipfrac_lower:7.668711623409763e-05 - actor/grad_norm:7.4742677211761475 - perf/mfu/actor:0.1769626378819161 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.77371978759766 - actor/lr:2e-06 - training/global_step:14 - training/epoch:0 - critic/rewards/mean:0.6173263788223267 - critic/rewards/max:0.9650354385375977 - critic/rewards/min:0.0 - critic/advantages/mean:0.14184120297431946 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.786576509475708 - response_length/mean:2.2865209579467773 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:40.8896484375 - prompt_length/max:127.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.9820013120770454e-06 - timing_s/generate_sequences:57.62593460083008 - timing_s/reshard:0.8097059726715088 - timing_s/gen:59.27430927599198 - timing_s/reward:0.6990328310057521 - timing_s/old_log_prob:2.2787000839889515 - timing_s/ref:2.3819664560141973 - timing_s/adv:0.4287329570215661 - timing_s/update_actor:10.86136281400104 - timing_s/step:76.02352630998939 - timing_s/stop_profile:3.755005309358239e-06 - timing_per_token_ms/update_actor:0.049132657072475036 - timing_per_token_ms/adv:0.0019394241508860037 - timing_per_token_ms/ref:0.010775106498663459 - timing_per_token_ms/gen:5.063156534923245 - perf/total_num_tokens:732039 - perf/time_per_step:76.02352630998939 - perf/throughput:1203.6389186537428
[36m(TaskRunner pid=1129931)[0m global_steps 15
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a Python function to find the length of the longest consecutive elements sequence in a list of integers. The sequence must be strictly consecutive, with no gaps between the numbers.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def longest_consecutive_sequence(nums): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res: 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     if not nums: end2prompt
[36m(TaskRunner pid=1129931)[0m second_res: 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:         return 0 end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt: 
[36m(TaskRunner pid=1129931)[0m     nums = set(nums) end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m Training Progress:   2%|▏         | 15/611 [18:37<12:29:52, 75.49s/it]
[36m(TaskRunner pid=1129931)[0m step:15 - global_seqlen/min:87583 - global_seqlen/max:101132 - global_seqlen/minmax_diff:13549 - global_seqlen/balanced_min:93047 - global_seqlen/balanced_max:93048 - global_seqlen/mean:93047.625 - actor/entropy:0.7386729121208191 - actor/pg_loss:-0.2180683701299131 - actor/pg_clipfrac:0.07356343034189194 - actor/ppo_kl:0.023062137683155015 - actor/pg_clipfrac_lower:0.00012833676009904593 - actor/grad_norm:5.380231440067291 - perf/mfu/actor:0.18650234010043315 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.81411361694336 - actor/lr:2e-06 - training/global_step:15 - training/epoch:0 - critic/rewards/mean:0.5835555791854858 - critic/rewards/max:0.9620223045349121 - critic/rewards/min:0.0 - critic/advantages/mean:0.17372675240039825 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.7499332427978516 - response_length/mean:2.5424399375915527 - response_length/max:19.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.9619140625 - prompt_length/max:124.0 - prompt_length/min:17.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:4.96100983582437e-06 - timing_s/generate_sequences:60.55853271484375 - timing_s/reshard:0.6577222943305969 - timing_s/gen:62.080584358016495 - timing_s/reward:0.7301155019958969 - timing_s/old_log_prob:2.6830594259954523 - timing_s/ref:2.5026963769923896 - timing_s/adv:0.4212028920010198 - timing_s/update_actor:10.477895493997494 - timing_s/step:79.0468506560137 - timing_s/stop_profile:2.7070054784417152e-06 - timing_per_token_ms/update_actor:0.04598345519300201 - timing_per_token_ms/adv:0.0018484975654307083 - timing_per_token_ms/ref:0.010983372260111372 - timing_per_token_ms/gen:4.769085950847148 - perf/total_num_tokens:744381 - perf/time_per_step:79.0468506560137 - perf/throughput:1177.1199513679949
[36m(TaskRunner pid=1129931)[0m global_steps 16
[36m(TaskRunner pid=1129931)[0m Training Progress:   3%|▎         | 16/611 [19:59<12:49:10, 77.56s/it]
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a Python function to determine if a given string is a valid word square. A word square is a set of words that can be arranged in a grid such that the same words can be read both horizontally and vertically. The words must be the same length.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def is_valid_word_square(words): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res:  
[36m(TaskRunner pid=1129931)[0m   
[36m(TaskRunner pid=1129931)[0m     # Get the number of rows 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     n = len(words) end2prompt
[36m(TaskRunner pid=1129931)[0m second_res:  
[36m(TaskRunner pid=1129931)[0m   
[36m(TaskRunner pid=1129931)[0m     # Check if every word has the same length  
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     for i in range(n): end3prompt
[36m(TaskRunner pid=1129931)[0m third_res: 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:         for j in range(n): end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res: 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m step:16 - global_seqlen/min:83730 - global_seqlen/max:100156 - global_seqlen/minmax_diff:16426 - global_seqlen/balanced_min:94424 - global_seqlen/balanced_max:94425 - global_seqlen/mean:94424.875 - actor/entropy:0.7203170657157898 - actor/pg_loss:-0.27818632214621175 - actor/pg_clipfrac:0.050845744204707444 - actor/ppo_kl:0.02573171838594135 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:6.796829581260681 - perf/mfu/actor:0.17187909453634556 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.71505355834961 - actor/lr:2e-06 - training/global_step:16 - training/epoch:0 - critic/rewards/mean:0.5895087122917175 - critic/rewards/max:0.9695805311203003 - critic/rewards/min:0.0 - critic/advantages/mean:0.23188379406929016 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.7513907551765442 - response_length/mean:3.1553573608398438 - response_length/max:18.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:41.5 - prompt_length/max:127.0 - prompt_length/min:19.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:1.951499143615365e-05 - timing_s/generate_sequences:61.95255661010742 - timing_s/reshard:0.6297032833099365 - timing_s/gen:63.46097790199565 - timing_s/reward:0.7399577549949754 - timing_s/old_log_prob:2.627345503977267 - timing_s/ref:2.664254945993889 - timing_s/adv:0.4867096859961748 - timing_s/update_actor:11.535378710977966 - timing_s/step:82.18150999600766 - timing_s/stop_profile:3.1329982448369265e-06 - timing_per_token_ms/update_actor:0.05045315473085067 - timing_per_token_ms/adv:0.002128758813371191 - timing_per_token_ms/ref:0.011652852533115298 - timing_per_token_ms/gen:3.928151657340166 - perf/total_num_tokens:755399 - perf/time_per_step:82.18150999600766 - perf/throughput:1148.979557622963
[36m(TaskRunner pid=1129931)[0m global_steps 17
[36m(TaskRunner pid=1129931)[0m Training Progress:   3%|▎         | 17/611 [21:18<12:52:07, 77.99s/it]
[36m(TaskRunner pid=1129931)[0m first_prompt: 
[36m(TaskRunner pid=1129931)[0m Write a python function to find the unique characters in a given string and return them in the order of their appearance.
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m 
[36m(TaskRunner pid=1129931)[0m ```python
[36m(TaskRunner pid=1129931)[0m def find_unique(string): end1prompt
[36m(TaskRunner pid=1129931)[0m first_res:  
[36m(TaskRunner pid=1129931)[0m     # using set 
[36m(TaskRunner pid=1129931)[0m  endfirst
[36m(TaskRunner pid=1129931)[0m second_prompt:     unique_chars = '' end2prompt
[36m(TaskRunner pid=1129931)[0m second_res:  
[36m(TaskRunner pid=1129931)[0m     
[36m(TaskRunner pid=1129931)[0m     # loop through 
[36m(TaskRunner pid=1129931)[0m  endsecond
[36m(TaskRunner pid=1129931)[0m third_prompt:     for char in string: end3prompt
[36m(TaskRunner pid=1129931)[0m third_res:  
[36m(TaskRunner pid=1129931)[0m         # check if character exists 
[36m(TaskRunner pid=1129931)[0m  endthird
[36m(TaskRunner pid=1129931)[0m fourth_prompt:         if char not in unique_chars: end3prompt
[36m(TaskRunner pid=1129931)[0m fourth_res:  
[36m(TaskRunner pid=1129931)[0m             # add character 
[36m(TaskRunner pid=1129931)[0m  endfourth
[36m(TaskRunner pid=1129931)[0m step:17 - global_seqlen/min:94476 - global_seqlen/max:105637 - global_seqlen/minmax_diff:11161 - global_seqlen/balanced_min:99803 - global_seqlen/balanced_max:99804 - global_seqlen/mean:99803.5 - actor/entropy:0.6930227875709534 - actor/pg_loss:-0.2665839437395334 - actor/pg_clipfrac:0.0488308307249099 - actor/ppo_kl:0.02208742804123176 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:6.676333159208298 - perf/mfu/actor:0.18697826430149864 - perf/max_memory_allocated_gb:23.579745292663574 - perf/max_memory_reserved_gb:41.994140625 - perf/cpu_memory_used_gb:81.76827621459961 - actor/lr:2e-06 - training/global_step:17 - training/epoch:0 - critic/rewards/mean:0.6041145920753479 - critic/rewards/max:0.9738355875015259 - critic/rewards/min:0.0 - critic/advantages/mean:0.2548219561576843 - critic/advantages/max:1.7888504266738892 - critic/advantages/min:-1.7888504266738892 - critic/format_reward/mean:0.7658594846725464 - response_length/mean:3.868593215942383 - response_length/max:32.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - prompt_length/mean:42.404296875 - prompt_length/max:123.0 - prompt_length/min:17.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.413981853052974e-06 - timing_s/generate_sequences:59.046546936035156 - timing_s/reshard:0.7910587191581726 - timing_s/gen:60.780716475012014 - timing_s/reward:0.7390256079961546 - timing_s/old_log_prob:2.777135088981595 - timing_s/ref:2.6033537869807333 - timing_s/adv:0.47061670999391936 - timing_s/update_actor:11.262141462008003 - timing_s/step:78.76094620401273 - timing_s/stop_profile:3.502005711197853e-06 - timing_per_token_ms/update_actor:0.0475361923574556 - timing_per_token_ms/adv:0.0019864185269179804 - timing_per_token_ms/ref:0.010988454265993722 - timing_per_token_ms/gen:3.0686177180905725 - perf/total_num_tokens:798428 - perf/time_per_step:78.76094620401273 - perf/throughput:1267.1698958704892
[36m(TaskRunner pid=1129931)[0m global_steps 18
*** SIGTERM received at time=1755640652 on cpu 125 ***
PC: @     0x7c49faa12117  (unknown)  (unknown)
    @     0x7c49fa9c3520  (unknown)  (unknown)
    @ ... and at least 1 more frames
[2025-08-19 21:57:32,385 E 1116915 1116915] logging.cc:501: *** SIGTERM received at time=1755640652 on cpu 125 ***
[2025-08-19 21:57:32,386 E 1116915 1116915] logging.cc:501: PC: @     0x7c49faa12117  (unknown)  (unknown)
[2025-08-19 21:57:32,386 E 1116915 1116915] logging.cc:501:     @     0x7c49fa9c3520  (unknown)  (unknown)
[2025-08-19 21:57:32,386 E 1116915 1116915] logging.cc:501:     @ ... and at least 1 more frames
